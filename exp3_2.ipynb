{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0+cu100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import io, img_as_uint, img_as_float\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义datasets\n",
    "class SAR_png_dataset(Dataset): \n",
    "    #因为以图像格式读入会快一些，直接读取csv loader很慢\n",
    "    def __init__(self, root_dir, info_csv,transform=None,transform_label=None): #__init__是初始化该类的一些基础参数 :'E:\\\\SAR\\\\exp3'\n",
    "        self.root_dir = root_dir   #文件目录\n",
    "        self.transform = transform #变换\n",
    "        self.transform_label=transform_label\n",
    "        self.files=pd.read_csv(os.path.join(self.root_dir,info_csv))\n",
    "        \n",
    "    def __len__(self):#返回整个数据集的大小files\n",
    "        return self.files.shape[0]\n",
    "    def __getitem__(self,index):#根据索引index返回dataset[index]\n",
    "        real_file = (self.files.iloc[index])['real'] #根据索引index获取该real文件名\n",
    "        imag_file = (self.files.iloc[index])['imag']\n",
    "        label_file = (self.files.iloc[index])['label']\n",
    "        io.use_plugin('matplotlib')\n",
    "        real=io.imread(os.path.join(self.root_dir,'real_img',real_file))\n",
    "        real_array=(np.array(real))[:,:,np.newaxis]\n",
    "        imag=io.imread(os.path.join(self.root_dir,'imag_img',imag_file))\n",
    "        imag_array=(np.array(imag))[:,:,np.newaxis]\n",
    "        data=np.concatenate((real_array,imag_array),axis=2)\n",
    "        label=io.imread(os.path.join(self.root_dir,'label_img',label_file))\n",
    "        label=2*label-1\n",
    "        #label=Image.open(os.path.join(self.root_dir,'label_img',label_file))\n",
    "        #label=np.asarray(label, dtype='float64') / 255\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)#对样本进行变换\n",
    "        if self.transform_label:\n",
    "            label=self.transform_label(label)\n",
    "        return data,label #返回该样本\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#预处理\n",
    "transform_data=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5),(0.5,0.5))])\n",
    "transform_label=transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset=  SAR_png_dataset('/home/are/SAR/SAR_exp3/exp3_2/dataset','SAR_datasets_info_train.csv',transform_data,transform_label)\n",
    "train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "valid_dataset=  SAR_png_dataset('/home/are/SAR/SAR_exp3/exp3_2/dataset','SAR_datasets_info_valid.csv',transform_data,transform_label)\n",
    "valid_loader=torch.utils.data.DataLoader(valid_dataset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self,shape):\n",
    "        super(View,self).__init__()\n",
    "        self.shape=shape\n",
    "    def forward(self,x):\n",
    "        return x.view(*self.shape)\n",
    "    \n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    __constants__ = ['downsample']\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out        \n",
    "class SAR_model(nn.Module):\n",
    "    def __init__(self, block, layers, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(SAR_model, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(2, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        #input:32,512,1,1\n",
    "        self.generator = nn.Sequential(\n",
    "            # input is Z, going into a convolution \n",
    "            nn.ConvTranspose2d( 512,256, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            # state size. 256*4*4\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            # state size. 128*8*8\n",
    "            nn.ConvTranspose2d( 128,64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            # state size. 64*16*16\n",
    "            nn.ConvTranspose2d( 64, 1, 5, 3, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. 1*48*48\n",
    "        )\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                #nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                #nn.init.constant_(m.weight, 1)\n",
    "                #nn.init.constant_(m.bias, 0)\n",
    "                nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "                nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x=self.generator(x)\n",
    "        \n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAR_model(\n",
      "  (conv1): Conv2d(2, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (generator): Sequential(\n",
      "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(64, 1, kernel_size=(5, 5), stride=(3, 3), padding=(1, 1), bias=False)\n",
      "    (10): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=SAR_model(block=BasicBlock,layers=[2,2,2,2])\n",
    "model=model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13,928,384 total parameters.\n",
      "13,928,384 training parameters.\n"
     ]
    }
   ],
   "source": [
    "#统计参数\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=5e-4\n",
    "criterion=nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),weight_decay=1e-4,lr=learning_rate,betas=(0.9,0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter  #写入tensorboard 路径可更改\n",
    "writer=SummaryWriter('/home/are/SAR/SAR_exp3/exp3_2/log/res_gan_valid_epoch500_time2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "0 epoch train loss: 0.00530758\n",
      "best valid loss: 1\n",
      "0 epoch valid loss: 0.00403201\n",
      "best valid loss: 0.0040320072881877425\n",
      "epoch: 1\n",
      "1 epoch train loss: 0.00136313\n",
      "best valid loss: 0.0040320072881877425\n",
      "1 epoch valid loss: 0.00270764\n",
      "best valid loss: 0.0027076407708227636\n",
      "epoch: 2\n",
      "2 epoch train loss: 0.00052911\n",
      "best valid loss: 0.0027076407708227636\n",
      "2 epoch valid loss: 0.00155879\n",
      "best valid loss: 0.001558790197595954\n",
      "epoch: 3\n",
      "3 epoch train loss: 0.00043830\n",
      "best valid loss: 0.001558790197595954\n",
      "3 epoch valid loss: 0.00148615\n",
      "best valid loss: 0.0014861495746299625\n",
      "epoch: 4\n",
      "4 epoch train loss: 0.00032983\n",
      "best valid loss: 0.0014861495746299625\n",
      "4 epoch valid loss: 0.00121245\n",
      "best valid loss: 0.0012124530039727688\n",
      "epoch: 5\n",
      "5 epoch train loss: 0.00029860\n",
      "best valid loss: 0.0012124530039727688\n",
      "5 epoch valid loss: 0.00117542\n",
      "best valid loss: 0.0011754242470487953\n",
      "epoch: 6\n",
      "6 epoch train loss: 0.00029174\n",
      "best valid loss: 0.0011754242470487953\n",
      "6 epoch valid loss: 0.00116266\n",
      "best valid loss: 0.001162656219676137\n",
      "epoch: 7\n",
      "7 epoch train loss: 0.00028251\n",
      "best valid loss: 0.001162656219676137\n",
      "7 epoch valid loss: 0.00114591\n",
      "best valid loss: 0.001145905158482492\n",
      "epoch: 8\n",
      "8 epoch train loss: 0.00026821\n",
      "best valid loss: 0.001145905158482492\n",
      "8 epoch valid loss: 0.00113484\n",
      "best valid loss: 0.0011348390625789762\n",
      "epoch: 9\n",
      "9 epoch train loss: 0.00024538\n",
      "best valid loss: 0.0011348390625789762\n",
      "9 epoch valid loss: 0.00098956\n",
      "best valid loss: 0.0009895559202414007\n",
      "epoch: 10\n",
      "10 epoch train loss: 0.00022928\n",
      "best valid loss: 0.0009895559202414007\n",
      "10 epoch valid loss: 0.00101657\n",
      "best valid loss: 0.0009895559202414007\n",
      "epoch: 11\n",
      "11 epoch train loss: 0.00021983\n",
      "best valid loss: 0.0009895559202414007\n",
      "11 epoch valid loss: 0.00111508\n",
      "best valid loss: 0.0009895559202414007\n",
      "epoch: 12\n",
      "12 epoch train loss: 0.00021004\n",
      "best valid loss: 0.0009895559202414007\n",
      "12 epoch valid loss: 0.00083860\n",
      "best valid loss: 0.0008385971514508128\n",
      "epoch: 13\n",
      "13 epoch train loss: 0.00020188\n",
      "best valid loss: 0.0008385971514508128\n",
      "13 epoch valid loss: 0.00108765\n",
      "best valid loss: 0.0008385971514508128\n",
      "epoch: 14\n",
      "14 epoch train loss: 0.00019294\n",
      "best valid loss: 0.0008385971514508128\n",
      "16 epoch valid loss: 0.00117563\n",
      "best valid loss: 0.0008385971514508128\n",
      "epoch: 17\n",
      "17 epoch train loss: 0.00016426\n",
      "best valid loss: 0.0008385971514508128\n",
      "17 epoch valid loss: 0.00107457\n",
      "best valid loss: 0.0008385971514508128\n",
      "epoch: 18\n",
      "18 epoch train loss: 0.00016221\n",
      "best valid loss: 0.0008385971514508128\n",
      "18 epoch valid loss: 0.00074229\n",
      "best valid loss: 0.000742291093338281\n",
      "epoch: 19\n",
      "19 epoch train loss: 0.00015905\n",
      "best valid loss: 0.000742291093338281\n",
      "19 epoch valid loss: 0.00089945\n",
      "best valid loss: 0.000742291093338281\n",
      "epoch: 20\n",
      "20 epoch train loss: 0.00015310\n",
      "best valid loss: 0.000742291093338281\n",
      "20 epoch valid loss: 0.00098222\n",
      "best valid loss: 0.000742291093338281\n",
      "epoch: 21\n",
      "21 epoch train loss: 0.00015299\n",
      "best valid loss: 0.000742291093338281\n",
      "21 epoch valid loss: 0.00106072\n",
      "best valid loss: 0.000742291093338281\n",
      "epoch: 22\n",
      "22 epoch train loss: 0.00014481\n",
      "best valid loss: 0.000742291093338281\n",
      "22 epoch valid loss: 0.00085717\n",
      "best valid loss: 0.000742291093338281\n",
      "epoch: 23\n",
      "23 epoch train loss: 0.00014022\n",
      "best valid loss: 0.000742291093338281\n",
      "23 epoch valid loss: 0.00059951\n",
      "best valid loss: 0.0005995124764740467\n",
      "epoch: 24\n",
      "24 epoch train loss: 0.00013889\n",
      "best valid loss: 0.0005995124764740467\n",
      "24 epoch valid loss: 0.00099185\n",
      "best valid loss: 0.0005995124764740467\n",
      "epoch: 25\n",
      "25 epoch train loss: 0.00013333\n",
      "best valid loss: 0.0005995124764740467\n",
      "25 epoch valid loss: 0.00081350\n",
      "best valid loss: 0.0005995124764740467\n",
      "epoch: 26\n",
      "26 epoch train loss: 0.00012868\n",
      "best valid loss: 0.0005995124764740467\n",
      "26 epoch valid loss: 0.00058007\n",
      "best valid loss: 0.0005800652131438256\n",
      "epoch: 27\n",
      "27 epoch train loss: 0.00012718\n",
      "best valid loss: 0.0005800652131438256\n",
      "27 epoch valid loss: 0.00076256\n",
      "best valid loss: 0.0005800652131438256\n",
      "epoch: 28\n",
      "28 epoch train loss: 0.00012783\n",
      "best valid loss: 0.0005800652131438256\n",
      "28 epoch valid loss: 0.00070951\n",
      "best valid loss: 0.0005800652131438256\n",
      "epoch: 29\n",
      "29 epoch train loss: 0.00011839\n",
      "best valid loss: 0.0005800652131438256\n",
      "29 epoch valid loss: 0.00069186\n",
      "best valid loss: 0.0005800652131438256\n",
      "epoch: 30\n",
      "30 epoch train loss: 0.00012116\n",
      "best valid loss: 0.0005800652131438256\n",
      "30 epoch valid loss: 0.00075697\n",
      "best valid loss: 0.0005800652131438256\n",
      "epoch: 31\n",
      "31 epoch train loss: 0.00011354\n",
      "best valid loss: 0.0005800652131438256\n",
      "31 epoch valid loss: 0.00047060\n",
      "best valid loss: 0.0004706022550817579\n",
      "epoch: 32\n",
      "32 epoch train loss: 0.00011356\n",
      "best valid loss: 0.0004706022550817579\n",
      "32 epoch valid loss: 0.00047181\n",
      "best valid loss: 0.0004706022550817579\n",
      "epoch: 33\n",
      "33 epoch train loss: 0.00011638\n",
      "best valid loss: 0.0004706022550817579\n",
      "33 epoch valid loss: 0.00064610\n",
      "best valid loss: 0.0004706022550817579\n",
      "epoch: 34\n",
      "34 epoch train loss: 0.00011010\n",
      "best valid loss: 0.0004706022550817579\n",
      "34 epoch valid loss: 0.00063341\n",
      "best valid loss: 0.0004706022550817579\n",
      "epoch: 35\n",
      "35 epoch train loss: 0.00010796\n",
      "best valid loss: 0.0004706022550817579\n",
      "35 epoch valid loss: 0.00053681\n",
      "best valid loss: 0.0004706022550817579\n",
      "epoch: 36\n",
      "36 epoch train loss: 0.00010690\n",
      "best valid loss: 0.0004706022550817579\n",
      "36 epoch valid loss: 0.00062710\n",
      "best valid loss: 0.0004706022550817579\n",
      "epoch: 37\n",
      "37 epoch train loss: 0.00010867\n",
      "best valid loss: 0.0004706022550817579\n",
      "37 epoch valid loss: 0.00069595\n",
      "best valid loss: 0.0004706022550817579\n",
      "epoch: 38\n",
      "38 epoch train loss: 0.00010708\n",
      "best valid loss: 0.0004706022550817579\n",
      "38 epoch valid loss: 0.00077310\n",
      "best valid loss: 0.0004706022550817579\n",
      "epoch: 39\n",
      "39 epoch train loss: 0.00010372\n",
      "best valid loss: 0.0004706022550817579\n",
      "39 epoch valid loss: 0.00038276\n",
      "best valid loss: 0.0003827637567883357\n",
      "epoch: 40\n",
      "40 epoch train loss: 0.00009811\n",
      "best valid loss: 0.0003827637567883357\n",
      "40 epoch valid loss: 0.00053858\n",
      "best valid loss: 0.0003827637567883357\n",
      "epoch: 41\n",
      "41 epoch train loss: 0.00009798\n",
      "best valid loss: 0.0003827637567883357\n",
      "41 epoch valid loss: 0.00075819\n",
      "best valid loss: 0.0003827637567883357\n",
      "epoch: 42\n",
      "42 epoch train loss: 0.00009834\n",
      "best valid loss: 0.0003827637567883357\n",
      "42 epoch valid loss: 0.00082541\n",
      "best valid loss: 0.0003827637567883357\n",
      "epoch: 43\n",
      "43 epoch train loss: 0.00009615\n",
      "best valid loss: 0.0003827637567883357\n",
      "43 epoch valid loss: 0.00047355\n",
      "best valid loss: 0.0003827637567883357\n",
      "epoch: 44\n",
      "44 epoch train loss: 0.00009186\n",
      "best valid loss: 0.0003827637567883357\n",
      "44 epoch valid loss: 0.00053044\n",
      "best valid loss: 0.0003827637567883357\n",
      "epoch: 45\n",
      "45 epoch train loss: 0.00008952\n",
      "best valid loss: 0.0003827637567883357\n",
      "45 epoch valid loss: 0.00066834\n",
      "best valid loss: 0.0003827637567883357\n",
      "epoch: 46\n",
      "46 epoch train loss: 0.00009226\n",
      "best valid loss: 0.0003827637567883357\n",
      "46 epoch valid loss: 0.00043726\n",
      "best valid loss: 0.0003827637567883357\n",
      "epoch: 47\n",
      "47 epoch train loss: 0.00008522\n",
      "best valid loss: 0.0003827637567883357\n",
      "47 epoch valid loss: 0.00037675\n",
      "best valid loss: 0.00037674758001230655\n",
      "epoch: 48\n",
      "48 epoch train loss: 0.00008757\n",
      "best valid loss: 0.00037674758001230655\n",
      "48 epoch valid loss: 0.00041791\n",
      "best valid loss: 0.00037674758001230655\n",
      "epoch: 49\n",
      "49 epoch train loss: 0.00008896\n",
      "best valid loss: 0.00037674758001230655\n",
      "49 epoch valid loss: 0.00041339\n",
      "best valid loss: 0.00037674758001230655\n",
      "epoch: 50\n",
      "50 epoch train loss: 0.00008483\n",
      "best valid loss: 0.00037674758001230655\n",
      "50 epoch valid loss: 0.00061635\n",
      "best valid loss: 0.00037674758001230655\n",
      "epoch: 51\n",
      "51 epoch train loss: 0.00008301\n",
      "best valid loss: 0.00037674758001230655\n",
      "51 epoch valid loss: 0.00042874\n",
      "best valid loss: 0.00037674758001230655\n",
      "epoch: 52\n",
      "52 epoch train loss: 0.00008353\n",
      "best valid loss: 0.00037674758001230655\n",
      "52 epoch valid loss: 0.00037999\n",
      "best valid loss: 0.00037674758001230655\n",
      "epoch: 53\n",
      "53 epoch train loss: 0.00007927\n",
      "best valid loss: 0.00037674758001230655\n",
      "53 epoch valid loss: 0.00036432\n",
      "best valid loss: 0.00036431589396670463\n",
      "epoch: 54\n",
      "54 epoch train loss: 0.00007659\n",
      "best valid loss: 0.00036431589396670463\n",
      "54 epoch valid loss: 0.00032274\n",
      "best valid loss: 0.00032273945456836375\n",
      "epoch: 55\n",
      "55 epoch train loss: 0.00007844\n",
      "best valid loss: 0.00032273945456836375\n",
      "55 epoch valid loss: 0.00033235\n",
      "best valid loss: 0.00032273945456836375\n",
      "epoch: 56\n",
      "56 epoch train loss: 0.00007719\n",
      "best valid loss: 0.00032273945456836375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 epoch valid loss: 0.00039147\n",
      "best valid loss: 0.00032273945456836375\n",
      "epoch: 57\n",
      "57 epoch train loss: 0.00007588\n",
      "best valid loss: 0.00032273945456836375\n",
      "57 epoch valid loss: 0.00036205\n",
      "best valid loss: 0.00032273945456836375\n",
      "epoch: 58\n",
      "58 epoch train loss: 0.00007674\n",
      "best valid loss: 0.00032273945456836375\n",
      "58 epoch valid loss: 0.00055209\n",
      "best valid loss: 0.00032273945456836375\n",
      "epoch: 59\n",
      "59 epoch train loss: 0.00007733\n",
      "best valid loss: 0.00032273945456836375\n",
      "59 epoch valid loss: 0.00030317\n",
      "best valid loss: 0.00030317077354993674\n",
      "epoch: 60\n",
      "60 epoch train loss: 0.00007072\n",
      "best valid loss: 0.00030317077354993674\n",
      "60 epoch valid loss: 0.00027356\n",
      "best valid loss: 0.0002735649049282074\n",
      "epoch: 61\n",
      "61 epoch train loss: 0.00006829\n",
      "best valid loss: 0.0002735649049282074\n",
      "61 epoch valid loss: 0.00033950\n",
      "best valid loss: 0.0002735649049282074\n",
      "epoch: 62\n",
      "62 epoch train loss: 0.00007313\n",
      "best valid loss: 0.0002735649049282074\n",
      "62 epoch valid loss: 0.00041657\n",
      "best valid loss: 0.0002735649049282074\n",
      "epoch: 63\n",
      "63 epoch train loss: 0.00006911\n",
      "best valid loss: 0.0002735649049282074\n",
      "63 epoch valid loss: 0.00037185\n",
      "best valid loss: 0.0002735649049282074\n",
      "epoch: 64\n",
      "64 epoch train loss: 0.00007016\n",
      "best valid loss: 0.0002735649049282074\n",
      "64 epoch valid loss: 0.00048610\n",
      "best valid loss: 0.0002735649049282074\n",
      "epoch: 65\n",
      "65 epoch train loss: 0.00006812\n",
      "best valid loss: 0.0002735649049282074\n",
      "65 epoch valid loss: 0.00035939\n",
      "best valid loss: 0.0002735649049282074\n",
      "epoch: 66\n",
      "66 epoch train loss: 0.00006622\n",
      "best valid loss: 0.0002735649049282074\n",
      "66 epoch valid loss: 0.00029845\n",
      "best valid loss: 0.0002735649049282074\n",
      "epoch: 67\n",
      "67 epoch train loss: 0.00006450\n",
      "best valid loss: 0.0002735649049282074\n",
      "67 epoch valid loss: 0.00024132\n",
      "best valid loss: 0.0002413212842657231\n",
      "epoch: 68\n",
      "68 epoch train loss: 0.00006461\n",
      "best valid loss: 0.0002413212842657231\n",
      "68 epoch valid loss: 0.00046091\n",
      "best valid loss: 0.0002413212842657231\n",
      "epoch: 69\n",
      "69 epoch train loss: 0.00006459\n",
      "best valid loss: 0.0002413212842657231\n",
      "69 epoch valid loss: 0.00028207\n",
      "best valid loss: 0.0002413212842657231\n",
      "epoch: 70\n",
      "70 epoch train loss: 0.00006361\n",
      "best valid loss: 0.0002413212842657231\n",
      "70 epoch valid loss: 0.00035835\n",
      "best valid loss: 0.0002413212842657231\n",
      "epoch: 71\n",
      "71 epoch train loss: 0.00005967\n",
      "best valid loss: 0.0002413212842657231\n",
      "71 epoch valid loss: 0.00025662\n",
      "best valid loss: 0.0002413212842657231\n",
      "epoch: 72\n",
      "72 epoch train loss: 0.00006085\n",
      "best valid loss: 0.0002413212842657231\n",
      "72 epoch valid loss: 0.00033318\n",
      "best valid loss: 0.0002413212842657231\n",
      "epoch: 73\n",
      "73 epoch train loss: 0.00006169\n",
      "best valid loss: 0.0002413212842657231\n",
      "73 epoch valid loss: 0.00030787\n",
      "best valid loss: 0.0002413212842657231\n",
      "epoch: 74\n",
      "74 epoch train loss: 0.00006109\n",
      "best valid loss: 0.0002413212842657231\n",
      "74 epoch valid loss: 0.00033175\n",
      "best valid loss: 0.0002413212842657231\n",
      "epoch: 75\n",
      "75 epoch train loss: 0.00005884\n",
      "best valid loss: 0.0002413212842657231\n",
      "75 epoch valid loss: 0.00023927\n",
      "best valid loss: 0.00023926854395540432\n",
      "epoch: 76\n",
      "76 epoch train loss: 0.00005749\n",
      "best valid loss: 0.00023926854395540432\n",
      "76 epoch valid loss: 0.00024786\n",
      "best valid loss: 0.00023926854395540432\n",
      "epoch: 77\n",
      "77 epoch train loss: 0.00005741\n",
      "best valid loss: 0.00023926854395540432\n",
      "77 epoch valid loss: 0.00033825\n",
      "best valid loss: 0.00023926854395540432\n",
      "epoch: 78\n",
      "78 epoch train loss: 0.00005790\n",
      "best valid loss: 0.00023926854395540432\n",
      "78 epoch valid loss: 0.00026799\n",
      "best valid loss: 0.00023926854395540432\n",
      "epoch: 79\n",
      "79 epoch train loss: 0.00005482\n",
      "best valid loss: 0.00023926854395540432\n",
      "79 epoch valid loss: 0.00027228\n",
      "best valid loss: 0.00023926854395540432\n",
      "epoch: 80\n",
      "80 epoch train loss: 0.00005543\n",
      "best valid loss: 0.00023926854395540432\n",
      "80 epoch valid loss: 0.00024654\n",
      "best valid loss: 0.00023926854395540432\n",
      "epoch: 81\n",
      "81 epoch train loss: 0.00005581\n",
      "best valid loss: 0.00023926854395540432\n",
      "81 epoch valid loss: 0.00028981\n",
      "best valid loss: 0.00023926854395540432\n",
      "epoch: 82\n",
      "82 epoch train loss: 0.00005676\n",
      "best valid loss: 0.00023926854395540432\n",
      "82 epoch valid loss: 0.00022607\n",
      "best valid loss: 0.0002260664975619875\n",
      "epoch: 83\n",
      "83 epoch train loss: 0.00005241\n",
      "best valid loss: 0.0002260664975619875\n",
      "83 epoch valid loss: 0.00022767\n",
      "best valid loss: 0.0002260664975619875\n",
      "epoch: 84\n",
      "84 epoch train loss: 0.00005623\n",
      "best valid loss: 0.0002260664975619875\n",
      "84 epoch valid loss: 0.00025161\n",
      "best valid loss: 0.0002260664975619875\n",
      "epoch: 85\n",
      "85 epoch train loss: 0.00005307\n",
      "best valid loss: 0.0002260664975619875\n",
      "85 epoch valid loss: 0.00022960\n",
      "best valid loss: 0.0002260664975619875\n",
      "epoch: 86\n",
      "86 epoch train loss: 0.00005103\n",
      "best valid loss: 0.0002260664975619875\n",
      "86 epoch valid loss: 0.00021909\n",
      "best valid loss: 0.00021908504975726829\n",
      "epoch: 87\n",
      "87 epoch train loss: 0.00005287\n",
      "best valid loss: 0.00021908504975726829\n",
      "87 epoch valid loss: 0.00023058\n",
      "best valid loss: 0.00021908504975726829\n",
      "epoch: 88\n",
      "88 epoch train loss: 0.00005038\n",
      "best valid loss: 0.00021908504975726829\n",
      "88 epoch valid loss: 0.00022627\n",
      "best valid loss: 0.00021908504975726829\n",
      "epoch: 89\n",
      "89 epoch train loss: 0.00005354\n",
      "best valid loss: 0.00021908504975726829\n",
      "89 epoch valid loss: 0.00022903\n",
      "best valid loss: 0.00021908504975726829\n",
      "epoch: 90\n",
      "90 epoch train loss: 0.00005269\n",
      "best valid loss: 0.00021908504975726829\n",
      "90 epoch valid loss: 0.00024578\n",
      "best valid loss: 0.00021908504975726829\n",
      "epoch: 91\n",
      "91 epoch train loss: 0.00005039\n",
      "best valid loss: 0.00021908504975726829\n",
      "91 epoch valid loss: 0.00022898\n",
      "best valid loss: 0.00021908504975726829\n",
      "epoch: 92\n",
      "92 epoch train loss: 0.00005025\n",
      "best valid loss: 0.00021908504975726829\n",
      "92 epoch valid loss: 0.00022867\n",
      "best valid loss: 0.00021908504975726829\n",
      "epoch: 93\n",
      "93 epoch train loss: 0.00004882\n",
      "best valid loss: 0.00021908504975726829\n",
      "93 epoch valid loss: 0.00020830\n",
      "best valid loss: 0.00020830191031564026\n",
      "epoch: 94\n",
      "94 epoch train loss: 0.00004753\n",
      "best valid loss: 0.00020830191031564026\n",
      "94 epoch valid loss: 0.00024187\n",
      "best valid loss: 0.00020830191031564026\n",
      "epoch: 95\n",
      "95 epoch train loss: 0.00004994\n",
      "best valid loss: 0.00020830191031564026\n",
      "95 epoch valid loss: 0.00024425\n",
      "best valid loss: 0.00020830191031564026\n",
      "epoch: 96\n",
      "96 epoch train loss: 0.00004787\n",
      "best valid loss: 0.00020830191031564026\n",
      "96 epoch valid loss: 0.00017432\n",
      "best valid loss: 0.00017431933170882985\n",
      "epoch: 97\n",
      "97 epoch train loss: 0.00004675\n",
      "best valid loss: 0.00017431933170882985\n",
      "97 epoch valid loss: 0.00017892\n",
      "best valid loss: 0.00017431933170882985\n",
      "epoch: 98\n",
      "98 epoch train loss: 0.00004562\n",
      "best valid loss: 0.00017431933170882985\n",
      "98 epoch valid loss: 0.00020243\n",
      "best valid loss: 0.00017431933170882985\n",
      "epoch: 99\n",
      "99 epoch train loss: 0.00004704\n",
      "best valid loss: 0.00017431933170882985\n",
      "99 epoch valid loss: 0.00022520\n",
      "best valid loss: 0.00017431933170882985\n",
      "epoch: 100\n",
      "100 epoch train loss: 0.00004702\n",
      "best valid loss: 0.00017431933170882985\n",
      "100 epoch valid loss: 0.00019266\n",
      "best valid loss: 0.00017431933170882985\n",
      "epoch: 101\n",
      "101 epoch train loss: 0.00004515\n",
      "best valid loss: 0.00017431933170882985\n",
      "101 epoch valid loss: 0.00018667\n",
      "best valid loss: 0.00017431933170882985\n",
      "epoch: 102\n",
      "102 epoch train loss: 0.00004441\n",
      "best valid loss: 0.00017431933170882985\n",
      "102 epoch valid loss: 0.00020314\n",
      "best valid loss: 0.00017431933170882985\n",
      "epoch: 103\n",
      "103 epoch train loss: 0.00004373\n",
      "best valid loss: 0.00017431933170882985\n",
      "103 epoch valid loss: 0.00016069\n",
      "best valid loss: 0.00016069400269770994\n",
      "epoch: 104\n",
      "104 epoch train loss: 0.00004697\n",
      "best valid loss: 0.00016069400269770994\n",
      "104 epoch valid loss: 0.00022038\n",
      "best valid loss: 0.00016069400269770994\n",
      "epoch: 105\n",
      "105 epoch train loss: 0.00004436\n",
      "best valid loss: 0.00016069400269770994\n",
      "105 epoch valid loss: 0.00017263\n",
      "best valid loss: 0.00016069400269770994\n",
      "epoch: 106\n",
      "106 epoch train loss: 0.00004233\n",
      "best valid loss: 0.00016069400269770994\n",
      "106 epoch valid loss: 0.00015961\n",
      "best valid loss: 0.0001596094114938751\n",
      "epoch: 107\n",
      "107 epoch train loss: 0.00004247\n",
      "best valid loss: 0.0001596094114938751\n",
      "107 epoch valid loss: 0.00017457\n",
      "best valid loss: 0.0001596094114938751\n",
      "epoch: 108\n",
      "108 epoch train loss: 0.00004445\n",
      "best valid loss: 0.0001596094114938751\n",
      "108 epoch valid loss: 0.00018829\n",
      "best valid loss: 0.0001596094114938751\n",
      "epoch: 109\n",
      "109 epoch train loss: 0.00004278\n",
      "best valid loss: 0.0001596094114938751\n",
      "109 epoch valid loss: 0.00017543\n",
      "best valid loss: 0.0001596094114938751\n",
      "epoch: 110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 epoch train loss: 0.00004232\n",
      "best valid loss: 0.0001596094114938751\n",
      "110 epoch valid loss: 0.00019058\n",
      "best valid loss: 0.0001596094114938751\n",
      "epoch: 111\n",
      "111 epoch train loss: 0.00004138\n",
      "best valid loss: 0.0001596094114938751\n",
      "111 epoch valid loss: 0.00017750\n",
      "best valid loss: 0.0001596094114938751\n",
      "epoch: 112\n",
      "112 epoch train loss: 0.00004133\n",
      "best valid loss: 0.0001596094114938751\n",
      "112 epoch valid loss: 0.00015742\n",
      "best valid loss: 0.00015741955605335533\n",
      "epoch: 113\n",
      "113 epoch train loss: 0.00004146\n",
      "best valid loss: 0.00015741955605335533\n",
      "113 epoch valid loss: 0.00020417\n",
      "best valid loss: 0.00015741955605335533\n",
      "epoch: 114\n",
      "114 epoch train loss: 0.00004029\n",
      "best valid loss: 0.00015741955605335533\n",
      "114 epoch valid loss: 0.00020112\n",
      "best valid loss: 0.00015741955605335533\n",
      "epoch: 115\n",
      "115 epoch train loss: 0.00004153\n",
      "best valid loss: 0.00015741955605335533\n",
      "115 epoch valid loss: 0.00022809\n",
      "best valid loss: 0.00015741955605335533\n",
      "epoch: 116\n",
      "116 epoch train loss: 0.00004086\n",
      "best valid loss: 0.00015741955605335533\n",
      "116 epoch valid loss: 0.00018968\n",
      "best valid loss: 0.00015741955605335533\n",
      "epoch: 117\n",
      "117 epoch train loss: 0.00003914\n",
      "best valid loss: 0.00015741955605335533\n",
      "117 epoch valid loss: 0.00018403\n",
      "best valid loss: 0.00015741955605335533\n",
      "epoch: 118\n",
      "118 epoch train loss: 0.00004012\n",
      "best valid loss: 0.00015741955605335533\n",
      "118 epoch valid loss: 0.00015428\n",
      "best valid loss: 0.00015427566613652744\n",
      "epoch: 119\n",
      "119 epoch train loss: 0.00003821\n",
      "best valid loss: 0.00015427566613652744\n",
      "119 epoch valid loss: 0.00015018\n",
      "best valid loss: 0.00015018220554338768\n",
      "epoch: 120\n",
      "120 epoch train loss: 0.00003936\n",
      "best valid loss: 0.00015018220554338768\n",
      "120 epoch valid loss: 0.00017474\n",
      "best valid loss: 0.00015018220554338768\n",
      "epoch: 121\n",
      "121 epoch train loss: 0.00003776\n",
      "best valid loss: 0.00015018220554338768\n",
      "121 epoch valid loss: 0.00013910\n",
      "best valid loss: 0.00013909804925788194\n",
      "epoch: 122\n",
      "122 epoch train loss: 0.00003851\n",
      "best valid loss: 0.00013909804925788194\n",
      "122 epoch valid loss: 0.00015916\n",
      "best valid loss: 0.00013909804925788194\n",
      "epoch: 123\n",
      "123 epoch train loss: 0.00003815\n",
      "best valid loss: 0.00013909804925788194\n",
      "123 epoch valid loss: 0.00015720\n",
      "best valid loss: 0.00013909804925788194\n",
      "epoch: 124\n",
      "124 epoch train loss: 0.00003784\n",
      "best valid loss: 0.00013909804925788194\n",
      "124 epoch valid loss: 0.00017025\n",
      "best valid loss: 0.00013909804925788194\n",
      "epoch: 125\n",
      "125 epoch train loss: 0.00003698\n",
      "best valid loss: 0.00013909804925788194\n",
      "125 epoch valid loss: 0.00013890\n",
      "best valid loss: 0.00013890499612898566\n",
      "epoch: 126\n",
      "126 epoch train loss: 0.00003746\n",
      "best valid loss: 0.00013890499612898566\n",
      "126 epoch valid loss: 0.00015051\n",
      "best valid loss: 0.00013890499612898566\n",
      "epoch: 127\n",
      "127 epoch train loss: 0.00003519\n",
      "best valid loss: 0.00013890499612898566\n"
     ]
    }
   ],
   "source": [
    "save_path='/home/are/SAR/SAR_exp3/exp3_2'\n",
    "num_epochs=500\n",
    "train_loss=[]\n",
    "valid_loss=[]\n",
    "best_loss=1\n",
    "dataloader={'train':train_loader,'valid':valid_loader}\n",
    "dataset={'train':train_dataset,'valid':valid_dataset}\n",
    "for epoch in range(num_epochs):\n",
    "    print('epoch:',epoch)\n",
    "    for phase in ['train','valid']:  \n",
    "        if phase=='train':\n",
    "            model.train(True)\n",
    "        else:\n",
    "            model.train(False) \n",
    "        running_loss=0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs,label=data\n",
    "            inputs=inputs.to(device)\n",
    "            label=label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss=criterion(outputs, label) \n",
    "            if phase=='train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            running_loss+=loss.item()\n",
    "            del outputs,label\n",
    "\n",
    "\n",
    "        epoch_loss=running_loss/len(dataset[phase])\n",
    "        if phase=='train':\n",
    "            writer.add_scalars('loss_train_val',{'train':epoch_loss},epoch)\n",
    "            train_loss.append(epoch_loss)\n",
    "            print('{} epoch {} loss: {:.8f}'.format(epoch,phase,epoch_loss))\n",
    "        if phase=='valid':\n",
    "            writer.add_scalars('loss_train_val',{'valid':epoch_loss},epoch)\n",
    "            valid_loss.append(epoch_loss)\n",
    "            if epoch_loss<best_loss:\n",
    "                best_loss=epoch_loss\n",
    "                best_model_wts=model.state_dict()\n",
    "            print('{} epoch {} loss: {:.8f}'.format(epoch,phase,epoch_loss))\n",
    "        print('best valid loss:',best_loss)\n",
    "    if epoch%50==0 and epoch!=0:\n",
    "        torch.save(best_model_wts,os.path.join(save_path,'best_weight_res_gan_valid_'+str(epoch)+'.pth'))\n",
    "        \n",
    "      \n",
    "            \n",
    "\n",
    "torch.save(best_model_wts,os.path.join(save_path,'best_weight_res_gan_valid_epoch500.pth'))\n",
    "#存储模型\n",
    "#torch.save(model.load_state_dict(best_model_wts),os.path.join(save_path,'best_model_res_gan_valid_epoch500.pth'))\n",
    "           \n",
    "with open(os.path.join(save_path,'train_loss.txt'),'w') as f:\n",
    "    for line in train_loss:\n",
    "        f.write(str(line)+'\\n')\n",
    "with open(os.path.join(save_path,'valid_loss.txt'),'w') as f:\n",
    "    for line in valid_loss:\n",
    "        f.write(str(line)+'\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model_wts,os.path.join(save_path,'best_weight_res_gan_valid_epoch500.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4ff3260c7eb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSAR_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBasicBlock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mload_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/home/are/SAR/SAR_exp3/exp3_2/best_weight_res_gan_valid_epoch500.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "model=SAR_model(block=BasicBlock,layers=[2,2,2,2])\n",
    "model=model.to(device)\n",
    "load_path='/home/are/SAR/SAR_exp3/exp3_2/best_weight_res_gan_valid_epoch500.pth'\n",
    "model.load_state_dict(torch.load(load_path))\n",
    "model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 2, 120, 540])\n",
      "torch.Size([64, 1, 48, 48])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3645eb6fde3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#inp=inputs[:,0,:,:].numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "def imshow(img):\n",
    "    npimg = np.squeeze(img.numpy())\n",
    "    #plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    print(npimg.shape)\n",
    "    plt.imshow(npimg)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "for i in range(32):\n",
    "    inputs=torch.unsqueeze(images[i,:,:,:],0)\n",
    "    \n",
    "    #inp=inputs[:,0,:,:].numpy()\n",
    "    #inp=np.squeeze(inp)\n",
    "    #np.savetxt('new_'+str(i)+'.csv', inp, delimiter = ',')  \n",
    "    inputs=inputs.to(device)\n",
    "    outputs=model(inputs)\n",
    "        #outputs=outputs.view((-1,1,120,91)) #[1, 512, 451]\n",
    "        \n",
    "    #print(outputs)\n",
    "    #print(outputs.shape)\n",
    "    #w=outputs.cpu().detach().numpy()\n",
    "    #ww= np.squeeze(w)\n",
    "    #print(ww.shape)\n",
    "    label=labels[i,:,:,:] #[1, 512, 451]\n",
    "    imshow(outputs.cpu().detach())\n",
    "    imshow(label)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight : torch.Size([64, 2, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([[[[ 4.9263e-40,  5.8838e-40,  5.7563e-41],\n",
      "          [-1.2276e-34,  1.8184e-38,  2.5367e-40],\n",
      "          [ 1.0157e-39,  3.0807e-40, -2.0890e-40]],\n",
      "\n",
      "         [[-7.3257e-37,  2.3926e-37,  3.7838e-37],\n",
      "          [-4.6251e-37, -7.1459e-39, -1.7811e-40],\n",
      "          [ 1.6163e-37,  2.1067e-40,  2.1171e-39]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6202e-34,  5.3704e-40, -5.2057e-40],\n",
      "          [-5.6085e-40, -8.8543e-34,  1.0954e-39],\n",
      "          [ 5.1050e-40,  1.1442e-39,  9.4326e-35]],\n",
      "\n",
      "         [[-2.0587e-34, -6.0086e-40, -2.9953e-35],\n",
      "          [ 2.6514e-33,  1.3645e-39,  1.8771e-36],\n",
      "          [-1.3276e-39,  1.6238e-39, -9.0727e-41]]],\n",
      "\n",
      "\n",
      "        [[[-2.2032e-40,  4.1497e-35, -3.3575e-36],\n",
      "          [ 4.8006e-40,  6.3554e-38, -5.5308e-40],\n",
      "          [ 4.9950e-36, -2.1975e-40, -1.8891e-35]],\n",
      "\n",
      "         [[ 5.9007e-40, -1.8512e-33,  3.1042e-40],\n",
      "          [ 2.3661e-35,  7.9169e-36, -5.4280e-40],\n",
      "          [ 2.0063e-33,  1.9766e-39,  9.7710e-41]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.7855e-36,  2.3594e-40,  9.2851e-36],\n",
      "          [ 1.8863e-33, -2.2360e-37,  3.2681e-40],\n",
      "          [ 8.4736e-40,  1.1405e-39,  3.6644e-40]],\n",
      "\n",
      "         [[-3.3769e-40,  3.0685e-34, -5.6425e-41],\n",
      "          [ 2.2279e-39, -1.8493e-36,  5.2366e-40],\n",
      "          [-4.1828e-40,  1.8472e-34,  5.9200e-37]]],\n",
      "\n",
      "\n",
      "        [[[-1.6080e-35,  3.1902e-34,  3.5089e-40],\n",
      "          [ 2.4165e-38, -7.6018e-34, -1.5699e-38],\n",
      "          [-1.4846e-39, -2.7526e-33,  7.2552e-36]],\n",
      "\n",
      "         [[ 1.7625e-33,  2.4748e-36, -2.1347e-41],\n",
      "          [-1.8485e-39,  5.8984e-40, -2.7384e-39],\n",
      "          [ 1.7059e-35, -2.8850e-39, -5.0362e-34]]],\n",
      "\n",
      "\n",
      "        [[[-7.3181e-37,  2.8449e-38, -1.9073e-38],\n",
      "          [ 1.4703e-35,  1.6025e-33, -3.2938e-38],\n",
      "          [ 2.8522e-40,  1.8554e-40, -1.0456e-33]],\n",
      "\n",
      "         [[ 1.5196e-41,  1.1639e-38,  5.0010e-40],\n",
      "          [-1.8217e-39, -2.0103e-34,  1.3350e-35],\n",
      "          [ 4.4178e-40,  3.8336e-40,  2.5972e-35]]]], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "features.0.bias : torch.Size([64])\n",
      "Parameter containing:\n",
      "tensor([ 1.8050e-37, -5.2589e-40,  3.9988e-38,  1.1338e-39,  4.0892e-37,\n",
      "         8.6281e-41,  1.5291e-33,  1.7374e-36,  2.3892e-36, -4.6418e-40,\n",
      "         2.5848e-40,  9.0278e-37, -7.0334e-35,  4.9618e-38, -1.7846e-36,\n",
      "         6.5741e-37,  5.4409e-40, -3.2100e-36,  2.4189e-36,  5.8843e-39,\n",
      "         3.8350e-39,  8.5223e-34,  2.4617e-41, -3.4144e-40, -3.3295e-42,\n",
      "        -1.7182e-35,  5.9987e-34, -5.7298e-40,  2.5345e-41, -2.4154e-40,\n",
      "         6.6858e-40,  9.1288e-39,  4.7334e-40,  1.0676e-36,  5.8605e-40,\n",
      "         9.2550e-37, -2.8192e-38, -1.8398e-37,  1.4270e-36,  1.2867e-36,\n",
      "         2.6860e-41,  7.2374e-41,  5.2185e-40, -3.5619e-40, -2.4841e-33,\n",
      "         2.0230e-33,  1.0150e-37,  5.9934e-42, -4.8406e-40, -8.8986e-39,\n",
      "         9.1213e-41,  5.7434e-40, -3.5210e-34, -4.3217e-41,  6.0963e-40,\n",
      "         5.8072e-40,  5.7231e-40,  5.0843e-34, -5.0895e-40,  2.4695e-36,\n",
      "        -2.6061e-38, -4.7258e-40,  2.5634e-33, -2.2350e-33], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "features.3.weight : torch.Size([128, 64, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([[[[ 6.1490e-40, -1.9822e-40, -4.9562e-40],\n",
      "          [ 5.1690e-40, -2.0232e-40, -4.9915e-40],\n",
      "          [ 2.9581e-42, -1.6125e-41, -1.9978e-41]],\n",
      "\n",
      "         [[-1.4824e-40, -1.7906e-41,  5.5209e-40],\n",
      "          [-5.4370e-40, -5.8129e-40,  5.2591e-40],\n",
      "          [ 5.4330e-40, -6.1389e-40,  1.7948e-40]],\n",
      "\n",
      "         [[-5.9495e-40,  5.8087e-40, -5.0309e-40],\n",
      "          [ 5.2380e-40, -6.6099e-42,  5.5285e-40],\n",
      "          [ 5.2056e-40, -1.4908e-40,  4.7824e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.5801e-40, -3.3118e-41,  5.6051e-40],\n",
      "          [ 3.3477e-41, -6.1411e-40,  3.4977e-40],\n",
      "          [-1.2962e-42, -6.1241e-40,  6.3011e-41]],\n",
      "\n",
      "         [[ 3.8867e-40,  5.5656e-40,  5.9180e-40],\n",
      "          [-4.8145e-40, -1.1405e-40,  2.8337e-41],\n",
      "          [ 5.0455e-40,  5.7353e-40, -5.5239e-40]],\n",
      "\n",
      "         [[-4.6490e-40, -4.9101e-41, -5.8676e-40],\n",
      "          [ 5.1115e-40, -4.1775e-40,  2.8528e-40],\n",
      "          [-5.4421e-40,  5.3688e-40, -5.1599e-41]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0255e-40,  5.1441e-40,  5.3144e-40],\n",
      "          [-8.0252e-42,  5.8198e-40, -5.9634e-40],\n",
      "          [-4.6342e-40, -5.9706e-40,  1.7217e-40]],\n",
      "\n",
      "         [[-6.1521e-40,  5.8812e-40,  2.7796e-41],\n",
      "          [ 5.6110e-40,  5.9253e-40, -3.5397e-41],\n",
      "          [ 3.9655e-41, -8.5333e-41,  5.6858e-40]],\n",
      "\n",
      "         [[-5.3401e-40, -2.1150e-40, -6.0449e-40],\n",
      "          [-4.8440e-41,  8.6670e-42,  3.4430e-41],\n",
      "          [-4.9753e-40, -2.9539e-41,  5.6685e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1743e-41,  6.0490e-40,  5.8738e-40],\n",
      "          [ 4.7298e-41, -5.1432e-40, -6.0190e-40],\n",
      "          [ 5.2449e-40, -1.5528e-41,  1.2120e-41]],\n",
      "\n",
      "         [[ 5.8137e-40, -2.1604e-40, -2.0325e-40],\n",
      "          [-5.6340e-40,  1.2255e-40,  2.1244e-40],\n",
      "          [ 5.2020e-40, -4.6387e-41, -5.2463e-40]],\n",
      "\n",
      "         [[-5.3072e-40,  6.0673e-40, -6.2255e-40],\n",
      "          [ 5.1796e-40, -2.1942e-40,  5.4276e-40],\n",
      "          [ 5.0900e-40,  6.2130e-40,  6.1891e-40]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8280e-40,  6.3629e-41,  5.5653e-40],\n",
      "          [ 6.0192e-40, -5.5063e-41, -5.1775e-41],\n",
      "          [-5.0785e-40, -5.4800e-40, -6.9014e-42]],\n",
      "\n",
      "         [[ 5.0634e-40,  4.9180e-41, -8.3559e-42],\n",
      "          [-4.8817e-40,  3.9472e-41, -5.2187e-40],\n",
      "          [-3.6023e-40, -5.1807e-40, -1.2271e-40]],\n",
      "\n",
      "         [[-4.5431e-40, -1.4809e-40,  5.3318e-40],\n",
      "          [ 4.9959e-40, -3.6553e-40,  3.5727e-40],\n",
      "          [ 5.7143e-40, -1.2079e-40,  3.3274e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.8835e-40,  5.6810e-41,  1.4550e-41],\n",
      "          [ 3.1721e-40,  6.1016e-40,  5.1359e-40],\n",
      "          [ 6.1429e-40, -5.7108e-40,  4.7822e-40]],\n",
      "\n",
      "         [[-8.2293e-41, -6.1856e-41,  3.3650e-40],\n",
      "          [-5.6061e-40, -3.9976e-40,  5.2501e-40],\n",
      "          [-4.1723e-40,  2.4961e-40, -5.2392e-40]],\n",
      "\n",
      "         [[ 5.2937e-40, -3.2691e-41, -5.6169e-40],\n",
      "          [ 2.1090e-41,  1.8208e-41,  7.8788e-41],\n",
      "          [-5.3993e-40, -5.5051e-40, -4.8379e-40]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.8492e-40,  1.8244e-40, -5.2726e-40],\n",
      "          [-5.1613e-40, -3.6808e-40,  1.1102e-41],\n",
      "          [ 3.1843e-41,  4.9008e-40,  1.9681e-40]],\n",
      "\n",
      "         [[ 5.6660e-40, -5.4060e-40,  1.3518e-41],\n",
      "          [ 3.5435e-40,  5.0385e-40, -4.7011e-40],\n",
      "          [ 6.3801e-42,  5.0947e-40,  3.3088e-40]],\n",
      "\n",
      "         [[-6.1744e-40,  4.6705e-40, -5.0548e-40],\n",
      "          [ 5.6750e-40, -4.8642e-40,  5.9176e-40],\n",
      "          [ 1.7801e-40, -6.2009e-40, -5.5239e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.5361e-40, -5.9167e-40, -2.1073e-40],\n",
      "          [-4.5872e-41, -5.5671e-40,  3.8877e-40],\n",
      "          [-5.3382e-40, -5.9619e-40,  7.0773e-41]],\n",
      "\n",
      "         [[-6.0122e-40, -3.7007e-41, -5.8904e-40],\n",
      "          [-5.3392e-40, -5.4323e-40,  5.1496e-40],\n",
      "          [-6.8285e-42, -3.0568e-41,  3.1857e-40]],\n",
      "\n",
      "         [[ 5.4028e-41,  5.0179e-40, -5.9724e-40],\n",
      "          [-1.5029e-41,  5.5986e-40, -5.1644e-40],\n",
      "          [-5.0382e-40, -3.3845e-40, -6.0331e-40]]],\n",
      "\n",
      "\n",
      "        [[[-5.8237e-40,  6.0991e-40,  5.7982e-40],\n",
      "          [-5.7595e-40, -4.8860e-40, -4.3485e-40],\n",
      "          [ 5.6387e-40, -5.6754e-40,  5.6505e-40]],\n",
      "\n",
      "         [[ 6.2147e-40,  4.8830e-40, -4.8670e-40],\n",
      "          [ 5.6299e-40, -5.4290e-40,  7.5065e-41],\n",
      "          [ 4.3753e-41,  5.3744e-40,  2.0127e-40]],\n",
      "\n",
      "         [[-5.8207e-40,  5.3288e-40, -1.9663e-41],\n",
      "          [ 1.7001e-40,  2.2326e-40, -4.9079e-40],\n",
      "          [ 2.7831e-40, -1.8012e-40,  6.3297e-42]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.8640e-40,  5.8233e-40, -3.3472e-40],\n",
      "          [ 4.6512e-41,  5.9175e-40, -5.8415e-40],\n",
      "          [-5.4724e-41, -5.4130e-40, -4.9193e-40]],\n",
      "\n",
      "         [[-5.0476e-40,  5.5058e-40,  3.1766e-41],\n",
      "          [ 5.1388e-40,  3.8904e-40,  4.8501e-40],\n",
      "          [-6.1979e-40,  5.0681e-40, -4.9783e-40]],\n",
      "\n",
      "         [[ 5.9212e-40,  3.0711e-40, -5.8529e-40],\n",
      "          [-4.2952e-40, -2.7828e-41, -3.3186e-40],\n",
      "          [ 9.8727e-41, -7.7179e-41, -5.9870e-40]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6704e-41,  3.0495e-41, -5.5847e-40],\n",
      "          [-6.0083e-40, -6.1094e-40, -5.9073e-40],\n",
      "          [ 3.3721e-40, -1.0880e-40,  5.5876e-40]],\n",
      "\n",
      "         [[-3.2531e-41, -6.0434e-40, -6.0373e-40],\n",
      "          [ 6.1735e-40,  5.0748e-40, -5.5954e-40],\n",
      "          [-2.1993e-40, -3.9306e-40, -2.5068e-40]],\n",
      "\n",
      "         [[-7.4955e-42, -5.2034e-40, -5.7881e-40],\n",
      "          [ 1.6899e-40,  4.2745e-40,  5.0424e-40],\n",
      "          [-4.9168e-40, -5.2993e-40,  5.9262e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5488e-40, -4.4471e-40,  3.3061e-41],\n",
      "          [-5.7756e-40, -3.5261e-40,  3.4916e-40],\n",
      "          [-8.9068e-41,  5.9884e-40,  6.8191e-41]],\n",
      "\n",
      "         [[ 4.8677e-40,  6.0740e-40,  5.6522e-40],\n",
      "          [-5.7746e-40, -5.3874e-40, -6.0419e-40],\n",
      "          [-5.9840e-40, -2.0238e-40,  2.5307e-40]],\n",
      "\n",
      "         [[-5.1228e-40, -5.5731e-40,  5.1413e-40],\n",
      "          [ 1.8745e-40, -5.0394e-40,  5.0067e-41],\n",
      "          [ 5.6633e-40, -4.8381e-40, -3.5245e-40]]]], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "features.3.bias : torch.Size([128])\n",
      "Parameter containing:\n",
      "tensor([ 5.7691e-40,  5.9101e-40,  9.0363e-41,  2.2737e-41, -4.4472e-40,\n",
      "        -2.0261e-40, -2.8470e-40, -5.1425e-40, -3.6478e-40,  5.3395e-40,\n",
      "         1.6185e-40, -5.4588e-40,  6.0944e-40, -1.8405e-41,  1.6460e-40,\n",
      "        -5.8222e-40, -5.0972e-40,  2.1340e-40,  3.0821e-40,  1.1045e-40,\n",
      "         5.4747e-40,  2.2105e-40, -4.8204e-40,  5.9230e-40, -4.9028e-40,\n",
      "        -1.8491e-40, -5.7971e-40, -5.8475e-40,  4.0936e-41, -4.4020e-40,\n",
      "         4.9784e-40, -6.1242e-40, -6.0445e-40,  5.7800e-40,  5.8643e-41,\n",
      "         5.7496e-40, -5.8168e-40,  5.3905e-40,  5.2307e-40, -7.5964e-42,\n",
      "        -4.8552e-40, -3.8816e-42,  2.3494e-41, -1.6974e-40, -5.0188e-40,\n",
      "        -5.1084e-40,  2.2128e-40, -5.5968e-40,  4.4715e-41,  5.9503e-40,\n",
      "        -3.1591e-40,  3.7629e-41, -3.1318e-40,  5.8148e-40, -5.0379e-40,\n",
      "        -3.9423e-40,  2.0053e-40,  5.5430e-40,  5.5315e-40,  4.4781e-41,\n",
      "        -5.5325e-40, -5.4712e-41,  5.4808e-40, -3.8377e-41,  1.2047e-40,\n",
      "         5.5614e-40,  3.2191e-41, -3.3190e-41, -5.3927e-40, -3.1449e-40,\n",
      "         6.1906e-40,  4.9756e-40, -2.7033e-40,  5.5714e-40,  3.9443e-40,\n",
      "         5.4684e-40, -5.8545e-40,  5.7347e-41,  5.6191e-40,  5.2499e-40,\n",
      "        -4.9469e-40, -2.5588e-41, -5.7248e-40, -5.5082e-40,  5.3504e-40,\n",
      "        -4.4928e-41, -8.7180e-41,  5.1188e-40, -5.6156e-40, -5.4607e-40,\n",
      "        -2.4590e-41,  3.1350e-40, -2.9878e-41,  1.6214e-41,  1.9745e-40,\n",
      "         5.2666e-40, -5.8972e-40,  1.0084e-41,  5.0404e-40,  5.8207e-41,\n",
      "        -5.8609e-40, -2.9399e-40, -2.7980e-40, -4.9073e-41, -4.3872e-41,\n",
      "         5.3039e-40, -3.7859e-41, -1.7837e-40, -2.4789e-41,  5.1809e-40,\n",
      "         1.9901e-40, -2.0149e-41,  5.1938e-40, -4.6649e-42,  5.4346e-40,\n",
      "        -5.2878e-41, -2.5691e-41,  5.1281e-40,  5.3135e-40,  1.0709e-40,\n",
      "        -5.7192e-40, -5.3488e-42, -5.9608e-40, -5.1381e-41, -2.6176e-41,\n",
      "         5.4947e-40, -4.8996e-40,  2.7299e-41], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "features.6.weight : torch.Size([256, 128, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([[[[-5.1340e-40, -2.0585e-40, -4.8705e-40],\n",
      "          [ 1.1867e-40,  5.0272e-40,  3.9036e-40],\n",
      "          [-5.4904e-40, -5.5555e-40,  4.9845e-40]],\n",
      "\n",
      "         [[ 6.0478e-40, -4.9669e-40,  5.4304e-40],\n",
      "          [ 5.7111e-40,  4.1336e-41, -5.7832e-42],\n",
      "          [-4.8736e-40,  3.8820e-40,  5.5649e-40]],\n",
      "\n",
      "         [[-4.9725e-40,  5.5618e-40, -4.5274e-40],\n",
      "          [ 5.6507e-40, -5.0042e-40, -6.0098e-40],\n",
      "          [-5.8705e-40, -5.6214e-40,  3.3216e-41]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.5037e-40,  5.3221e-42,  4.5122e-43],\n",
      "          [ 4.8806e-40, -5.2624e-40, -2.7849e-40],\n",
      "          [ 1.1747e-41,  6.0045e-40, -3.1214e-40]],\n",
      "\n",
      "         [[ 4.4719e-40, -5.0493e-40, -6.0208e-40],\n",
      "          [ 2.5895e-41,  5.8565e-40, -4.2968e-40],\n",
      "          [ 1.0391e-40,  3.7647e-41, -1.0032e-40]],\n",
      "\n",
      "         [[-5.1743e-40, -4.9473e-41, -2.5599e-41],\n",
      "          [-6.6403e-41, -4.7469e-41, -5.2105e-40],\n",
      "          [ 4.9599e-41, -5.9769e-40,  5.6592e-40]]],\n",
      "\n",
      "\n",
      "        [[[-4.0720e-41,  5.7194e-40, -5.2522e-40],\n",
      "          [ 5.3046e-41,  5.3121e-40,  7.9248e-41],\n",
      "          [ 6.5748e-41,  5.2232e-40,  5.1973e-40]],\n",
      "\n",
      "         [[-5.5391e-40, -5.6870e-40,  1.0550e-41],\n",
      "          [-3.8641e-41,  4.3000e-41,  5.8021e-40],\n",
      "          [ 4.5807e-41,  3.3585e-41,  5.5876e-40]],\n",
      "\n",
      "         [[ 1.9565e-40, -5.7657e-40, -3.8112e-40],\n",
      "          [-4.8932e-40,  4.1405e-40,  1.4143e-40],\n",
      "          [-4.8937e-40, -2.1364e-40, -5.4081e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9461e-41, -5.8689e-40,  5.4853e-40],\n",
      "          [-4.9963e-40, -4.6482e-41, -5.1759e-40],\n",
      "          [ 5.0519e-40,  1.8314e-41, -6.0164e-40]],\n",
      "\n",
      "         [[ 2.4432e-41,  5.0642e-40,  5.8939e-40],\n",
      "          [-1.6670e-41, -3.1735e-40, -5.4053e-40],\n",
      "          [-5.0897e-40,  5.4474e-40,  5.2888e-40]],\n",
      "\n",
      "         [[-3.0274e-40,  5.6375e-40,  7.8219e-41],\n",
      "          [ 5.9390e-40, -3.7857e-41, -6.1127e-40],\n",
      "          [-5.8253e-40,  5.7040e-40,  3.7060e-40]]],\n",
      "\n",
      "\n",
      "        [[[-5.4686e-40, -4.0102e-40, -6.1250e-40],\n",
      "          [-5.5161e-40, -4.0523e-40, -3.9908e-40],\n",
      "          [ 5.2226e-40, -9.7474e-42,  5.8505e-40]],\n",
      "\n",
      "         [[ 5.4002e-41,  5.2490e-40,  6.1679e-40],\n",
      "          [-4.2630e-41, -5.2505e-40, -1.2560e-41],\n",
      "          [-5.1115e-40, -5.0158e-40,  1.6998e-41]],\n",
      "\n",
      "         [[-6.0020e-40, -5.2646e-40, -4.9832e-40],\n",
      "          [-5.3203e-40, -4.2880e-42,  5.8386e-40],\n",
      "          [-5.4019e-40, -5.2934e-40, -1.3985e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4306e-40, -5.1555e-40,  6.8050e-41],\n",
      "          [ 4.1573e-40, -5.9083e-40, -2.1911e-40],\n",
      "          [-5.0162e-40,  5.8856e-40,  1.8629e-41]],\n",
      "\n",
      "         [[-5.9228e-40,  1.4213e-40,  5.4513e-40],\n",
      "          [ 3.4468e-40,  5.2024e-40,  5.8837e-40],\n",
      "          [ 4.7913e-41, -2.6835e-40,  6.0156e-40]],\n",
      "\n",
      "         [[ 5.5752e-40,  5.0542e-40,  5.4294e-40],\n",
      "          [-3.1211e-40,  5.7938e-40,  5.5514e-40],\n",
      "          [-4.8167e-40,  1.0613e-40, -6.0351e-40]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 5.6054e-40, -4.9918e-40, -4.9029e-40],\n",
      "          [ 4.4494e-40,  5.9052e-40, -3.5802e-41],\n",
      "          [ 2.0776e-41,  5.3459e-40, -5.2916e-40]],\n",
      "\n",
      "         [[ 5.9480e-40,  7.6389e-41, -5.8224e-40],\n",
      "          [-3.8877e-40, -5.6062e-40, -5.6859e-40],\n",
      "          [-1.6241e-40,  5.2994e-40, -5.7472e-40]],\n",
      "\n",
      "         [[ 4.6177e-41, -3.9584e-41,  4.4807e-40],\n",
      "          [ 5.1956e-40, -4.7994e-41,  4.8347e-40],\n",
      "          [-5.8757e-40,  3.5068e-40, -1.2666e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.8052e-40, -1.0106e-41, -5.8952e-40],\n",
      "          [-6.0148e-40,  4.8292e-40, -3.3481e-40],\n",
      "          [ 8.1626e-42,  5.6293e-40,  5.2310e-40]],\n",
      "\n",
      "         [[-1.2386e-40,  1.4623e-41, -4.5395e-40],\n",
      "          [ 5.4282e-40, -2.3309e-41,  4.9421e-40],\n",
      "          [-6.1199e-40,  5.0523e-40,  5.9768e-40]],\n",
      "\n",
      "         [[ 5.3863e-40, -3.6317e-41,  3.6284e-41],\n",
      "          [-5.5651e-40, -3.5582e-41, -1.4293e-43],\n",
      "          [ 3.5059e-40,  1.0609e-40,  5.3590e-40]]],\n",
      "\n",
      "\n",
      "        [[[-3.5755e-40, -7.6648e-41, -5.4697e-40],\n",
      "          [ 5.4619e-40, -5.0424e-40,  4.9828e-40],\n",
      "          [-2.8102e-41,  5.7484e-41,  4.0692e-41]],\n",
      "\n",
      "         [[ 5.9450e-40,  5.9167e-40, -4.9552e-40],\n",
      "          [-6.8117e-42, -3.2901e-41, -3.4262e-40],\n",
      "          [ 2.6270e-41, -1.2878e-42, -5.3665e-40]],\n",
      "\n",
      "         [[ 5.3195e-40, -4.0033e-40, -1.6675e-42],\n",
      "          [-1.0411e-40, -5.2244e-40,  4.9415e-40],\n",
      "          [ 4.8325e-40, -5.3146e-40,  4.8171e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7147e-40, -4.9143e-40, -5.1719e-41],\n",
      "          [-5.7663e-40, -2.4033e-40, -2.0805e-40],\n",
      "          [ 2.7129e-42,  4.8647e-40, -5.5362e-40]],\n",
      "\n",
      "         [[-5.3248e-40,  5.3786e-40, -4.9225e-40],\n",
      "          [ 4.8357e-41, -5.7303e-40,  3.7026e-40],\n",
      "          [ 5.5668e-40,  1.3108e-41,  2.4368e-40]],\n",
      "\n",
      "         [[ 5.7448e-40,  5.7519e-41, -1.3712e-41],\n",
      "          [ 5.7171e-40, -5.5066e-40, -5.9271e-40],\n",
      "          [ 6.1085e-40, -4.1675e-41,  4.9305e-40]]],\n",
      "\n",
      "\n",
      "        [[[-3.2195e-40, -5.1812e-40,  5.4527e-40],\n",
      "          [-5.2560e-40,  3.7983e-40, -2.2328e-40],\n",
      "          [-5.6436e-40, -1.4154e-40,  4.9633e-40]],\n",
      "\n",
      "         [[-6.1236e-40, -5.7325e-40,  5.8927e-41],\n",
      "          [-5.3109e-40, -5.6230e-40, -4.7611e-40],\n",
      "          [ 6.1934e-40, -5.3934e-40,  6.1106e-40]],\n",
      "\n",
      "         [[ 4.8847e-40, -1.5947e-41, -5.7196e-40],\n",
      "          [-3.5961e-40,  4.8337e-40, -2.3273e-41],\n",
      "          [ 3.0936e-40, -3.0018e-40, -5.5919e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4130e-40, -5.2539e-40,  4.1953e-41],\n",
      "          [-5.0033e-40, -5.7143e-40, -4.9983e-40],\n",
      "          [ 1.9829e-40, -5.4422e-41, -6.1271e-40]],\n",
      "\n",
      "         [[-4.1885e-41, -2.1913e-40,  4.8668e-40],\n",
      "          [ 5.8610e-40,  5.8845e-40,  5.3672e-40],\n",
      "          [-4.2408e-40,  6.1484e-40, -5.4284e-40]],\n",
      "\n",
      "         [[-6.2034e-40, -4.1827e-41,  8.7867e-41],\n",
      "          [-5.3628e-42,  1.0578e-40, -5.0790e-40],\n",
      "          [-5.8146e-40, -5.8308e-42, -5.4377e-40]]]], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "features.6.bias : torch.Size([256])\n",
      "Parameter containing:\n",
      "tensor([ 5.6550e-40,  5.9751e-40,  5.0621e-40, -5.2512e-40, -5.3895e-40,\n",
      "         6.0837e-41,  3.7100e-40,  5.3995e-40, -3.7508e-40, -5.6401e-40,\n",
      "         5.2711e-40,  5.5726e-40, -5.2033e-40, -5.2918e-40, -5.8101e-40,\n",
      "         5.2050e-40, -3.6766e-41,  1.9304e-40, -4.8102e-40, -4.3361e-40,\n",
      "         4.0644e-40,  4.9534e-40, -6.0786e-40, -4.0623e-40, -5.7896e-40,\n",
      "        -5.4670e-40, -1.0419e-41,  2.4517e-40,  3.7680e-41,  9.4476e-42,\n",
      "         5.4743e-41,  5.5040e-40,  1.8038e-40,  4.0427e-41, -4.9068e-40,\n",
      "         4.1547e-40,  3.6460e-40, -6.8102e-41,  1.8932e-41,  3.5949e-41,\n",
      "         1.1312e-40,  5.2228e-40,  5.2303e-40,  5.6436e-40,  3.3495e-40,\n",
      "        -5.4059e-40, -2.0365e-40,  1.0466e-41,  5.7565e-40,  1.3745e-40,\n",
      "        -4.1855e-40,  3.7687e-40,  4.6562e-41,  3.3125e-40, -5.1518e-40,\n",
      "         5.3755e-40,  6.0101e-40, -4.6714e-40, -6.0808e-40, -5.8021e-40,\n",
      "        -3.6307e-40,  6.1736e-41,  2.3337e-40,  6.0085e-40,  2.4959e-41,\n",
      "        -4.8091e-40,  5.1757e-40,  5.2195e-40, -3.5383e-40,  5.4043e-40,\n",
      "        -6.2408e-41,  5.7418e-40,  2.0210e-40, -3.4708e-40,  5.1940e-40,\n",
      "         5.7021e-40,  5.4298e-40,  6.0113e-40,  5.3349e-40,  6.0642e-40,\n",
      "        -5.6605e-40, -6.7747e-41,  2.2056e-41,  6.1128e-40, -5.2709e-40,\n",
      "         5.7795e-40, -4.8761e-40,  5.4586e-40, -3.0743e-40, -5.0797e-40,\n",
      "        -5.6322e-40, -4.1242e-40, -4.3709e-41,  5.8586e-40,  5.0073e-40,\n",
      "        -6.4684e-42, -2.3153e-40, -2.1860e-40,  2.0385e-40,  6.1093e-40,\n",
      "         5.3896e-40,  5.1991e-40,  2.6824e-41, -1.1541e-41,  2.6845e-40,\n",
      "         3.9825e-40, -3.6111e-42,  4.4608e-40, -2.9497e-42,  5.1300e-40,\n",
      "         1.2995e-40,  1.8956e-40,  1.9692e-40,  5.9084e-40, -1.5929e-40,\n",
      "        -3.6004e-41, -3.8417e-40, -5.2259e-40,  2.0334e-40,  1.2405e-40,\n",
      "        -5.5241e-41,  5.6836e-40, -3.7006e-40, -5.1171e-40, -5.2014e-40,\n",
      "         5.1814e-40,  1.7847e-41, -3.3456e-40, -4.4825e-40,  1.3730e-40,\n",
      "        -5.1227e-40, -5.4237e-40, -6.0905e-40, -5.2141e-40, -1.6528e-41,\n",
      "        -5.1962e-40,  2.1417e-40, -4.2902e-40,  6.0575e-40, -2.3704e-40,\n",
      "        -5.5549e-40,  3.2573e-40, -5.3913e-40,  5.0221e-40, -5.0205e-40,\n",
      "         3.6798e-42,  6.8972e-42,  5.2935e-40,  5.2179e-40, -5.6424e-40,\n",
      "         3.4635e-40, -5.2884e-40,  5.8307e-40, -4.8924e-40,  4.3773e-40,\n",
      "        -5.6274e-40,  5.1328e-40, -2.1105e-40,  5.7491e-40,  3.7558e-41,\n",
      "         6.1567e-40,  1.1160e-40, -5.4324e-40,  6.8491e-41, -4.8512e-40,\n",
      "        -6.0514e-40,  8.8918e-41, -2.9119e-41, -5.4512e-40,  1.5631e-40,\n",
      "        -4.4531e-40,  4.9679e-41, -8.8292e-41,  5.3436e-40,  2.9788e-40,\n",
      "        -4.7506e-40,  9.9590e-42, -2.1065e-40, -5.8232e-40,  1.9646e-40,\n",
      "         5.3726e-40, -4.9427e-40,  1.1212e-40, -3.3219e-41, -5.3860e-40,\n",
      "        -4.8750e-41,  5.2326e-40, -5.6656e-41,  3.2038e-41,  7.3735e-41,\n",
      "         5.3183e-40, -5.2102e-40,  2.9838e-41, -5.5762e-40,  6.1491e-40,\n",
      "        -2.9181e-41, -5.2027e-40,  5.3782e-40, -3.0306e-41, -4.9915e-40,\n",
      "        -5.6410e-40, -5.3156e-40, -5.3331e-40, -2.4735e-40,  5.6188e-40,\n",
      "         4.5119e-41, -1.2256e-40, -5.8597e-40, -2.9699e-41,  5.4767e-40,\n",
      "         5.7370e-40,  2.6330e-40, -4.9123e-40, -5.9040e-40,  5.4074e-40,\n",
      "        -2.2372e-41,  1.5275e-40, -5.4141e-40, -3.0326e-40,  1.8609e-40,\n",
      "        -1.5359e-40, -3.4025e-40,  5.2196e-40,  5.3643e-40,  4.5917e-40,\n",
      "         3.7325e-41, -5.9201e-40, -4.8618e-40,  5.2953e-40, -1.4627e-40,\n",
      "         1.2611e-40,  4.9501e-40, -2.9880e-40, -5.2874e-40, -6.1165e-40,\n",
      "        -7.9622e-41,  5.7406e-40, -5.9756e-40, -5.7986e-40, -5.2757e-40,\n",
      "        -1.1241e-40,  5.3170e-40,  2.9548e-40, -6.6748e-41,  5.7560e-40,\n",
      "         9.7348e-42,  5.5292e-40,  2.4252e-40, -3.3756e-40, -5.9317e-41,\n",
      "         2.9640e-41,  2.2036e-40, -4.7602e-40,  5.9022e-40,  5.2167e-40,\n",
      "         5.1305e-40], device='cuda:1', requires_grad=True)\n",
      "features.8.weight : torch.Size([256, 256, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([[[[-6.1671e-40, -3.7472e-40, -5.2351e-41],\n",
      "          [ 5.3020e-40,  5.7652e-40,  5.5592e-40],\n",
      "          [ 5.1176e-40,  5.6061e-40,  3.2366e-41]],\n",
      "\n",
      "         [[-1.3114e-40,  9.7748e-41,  5.6466e-40],\n",
      "          [-5.5828e-40, -3.5140e-40, -5.5518e-40],\n",
      "          [-1.7385e-40,  5.2726e-40,  6.1661e-40]],\n",
      "\n",
      "         [[-5.1634e-40, -5.6214e-40, -1.0311e-40],\n",
      "          [-4.8522e-40,  6.1964e-40, -2.1040e-40],\n",
      "          [ 5.3312e-40,  3.9275e-40, -5.8767e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2351e-40, -3.6573e-40, -5.6878e-40],\n",
      "          [ 5.0261e-40, -4.9163e-40, -5.0118e-40],\n",
      "          [-6.0592e-40, -5.4684e-40,  1.8267e-40]],\n",
      "\n",
      "         [[ 5.0880e-40,  2.8353e-40, -3.5478e-40],\n",
      "          [ 5.2993e-40,  5.7337e-40, -2.6123e-40],\n",
      "          [ 4.9144e-40,  5.1306e-40, -4.8122e-40]],\n",
      "\n",
      "         [[-5.8032e-40,  6.3250e-41,  3.3437e-40],\n",
      "          [-3.1333e-41,  5.0104e-40, -5.8231e-40],\n",
      "          [-5.7330e-40, -1.3703e-40,  5.0288e-40]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4645e-41, -4.8821e-40,  6.7701e-41],\n",
      "          [ 8.5902e-41, -5.4045e-40, -1.6551e-40],\n",
      "          [-6.4420e-41, -1.5155e-40,  6.0047e-40]],\n",
      "\n",
      "         [[ 1.9264e-41, -5.5030e-40,  5.6874e-40],\n",
      "          [-4.8095e-40, -3.6132e-41, -5.7345e-41],\n",
      "          [ 6.1791e-40, -1.3976e-40,  3.9585e-41]],\n",
      "\n",
      "         [[-5.9463e-40,  6.0438e-40,  5.3094e-40],\n",
      "          [-6.2140e-40,  5.2111e-41, -5.7511e-40],\n",
      "          [ 1.2528e-40,  3.8849e-40, -5.0276e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6186e-40,  5.5531e-40, -4.8140e-40],\n",
      "          [-5.5437e-40,  6.1507e-40,  5.2117e-40],\n",
      "          [ 2.2948e-41,  5.9885e-40, -6.0658e-41]],\n",
      "\n",
      "         [[ 6.1177e-40, -1.6350e-41,  4.8784e-40],\n",
      "          [-2.3402e-42, -5.1325e-40, -6.1961e-40],\n",
      "          [-4.8315e-40,  5.0556e-40,  5.7950e-40]],\n",
      "\n",
      "         [[-6.7505e-41, -1.5501e-41,  6.9504e-43],\n",
      "          [-5.1857e-40,  4.9432e-40, -5.0348e-40],\n",
      "          [ 4.8760e-40, -1.4806e-40,  1.9886e-40]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5808e-40,  1.9479e-41, -5.4859e-41],\n",
      "          [ 5.1508e-40,  9.7417e-41,  1.9459e-40],\n",
      "          [ 9.1857e-41,  1.5556e-41,  1.3663e-40]],\n",
      "\n",
      "         [[ 4.4830e-41, -5.1348e-40,  4.8966e-40],\n",
      "          [-5.3857e-40,  6.1827e-40,  3.9712e-40],\n",
      "          [ 5.5545e-40, -3.2579e-40, -6.1237e-40]],\n",
      "\n",
      "         [[-4.9275e-40,  6.1984e-40,  5.4788e-40],\n",
      "          [-5.7786e-40, -1.4273e-40, -5.9338e-40],\n",
      "          [-4.9932e-40,  5.4226e-40,  5.7588e-41]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3900e-40,  4.8122e-40, -5.6130e-40],\n",
      "          [ 5.6930e-40, -6.1638e-40, -3.9409e-40],\n",
      "          [ 2.4317e-41, -1.3621e-41,  4.9087e-40]],\n",
      "\n",
      "         [[-3.9994e-40, -5.9101e-40,  5.1711e-40],\n",
      "          [-5.0456e-40,  4.7756e-41, -5.5692e-40],\n",
      "          [ 3.6991e-41, -5.7565e-41,  5.6246e-40]],\n",
      "\n",
      "         [[-1.5267e-41,  5.0053e-40,  3.7337e-40],\n",
      "          [-5.9834e-40,  5.7533e-40,  5.0255e-40],\n",
      "          [-5.2186e-41, -2.4593e-41, -3.4798e-40]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.1967e-41, -6.0298e-40, -5.3184e-40],\n",
      "          [-6.1487e-40,  6.5434e-41,  4.2547e-40],\n",
      "          [ 3.9590e-40,  3.2926e-40,  6.1814e-40]],\n",
      "\n",
      "         [[-6.5327e-41,  4.5885e-40,  5.6443e-40],\n",
      "          [-1.4009e-40, -4.8990e-40, -5.9572e-40],\n",
      "          [ 1.3061e-40,  5.2704e-40, -5.8248e-40]],\n",
      "\n",
      "         [[ 1.2762e-40, -4.8656e-40,  3.4934e-40],\n",
      "          [ 5.3898e-40, -5.6698e-40, -5.3582e-40],\n",
      "          [ 4.3059e-40,  4.8960e-41,  4.9523e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.4403e-41, -5.0786e-40, -5.0750e-40],\n",
      "          [ 1.9323e-41,  5.2662e-40, -2.2134e-41],\n",
      "          [ 4.6372e-41,  1.3902e-41,  5.8452e-40]],\n",
      "\n",
      "         [[-4.3435e-40, -2.1213e-41,  5.0913e-40],\n",
      "          [-5.3169e-40,  5.4940e-40, -4.1222e-41],\n",
      "          [-6.1076e-40,  5.1868e-40, -4.8789e-40]],\n",
      "\n",
      "         [[ 9.2376e-41, -5.7987e-40, -4.9201e-40],\n",
      "          [-2.9102e-40, -4.8380e-40,  5.1004e-40],\n",
      "          [ 3.8395e-40, -6.2154e-40, -6.0659e-41]]],\n",
      "\n",
      "\n",
      "        [[[-4.9828e-40, -5.5139e-40,  3.5576e-40],\n",
      "          [-5.9946e-40, -5.2088e-40, -4.8170e-41],\n",
      "          [-6.8860e-41,  5.8501e-40, -2.1284e-40]],\n",
      "\n",
      "         [[-1.6774e-41,  2.2651e-40, -6.1919e-40],\n",
      "          [-4.0293e-40, -4.1598e-41,  2.5145e-41],\n",
      "          [-4.9215e-40, -6.1904e-40,  6.1299e-40]],\n",
      "\n",
      "         [[ 3.8358e-40,  4.9724e-40,  3.1025e-40],\n",
      "          [ 5.2451e-41, -5.3698e-40, -5.9807e-40],\n",
      "          [ 2.4551e-41,  5.5492e-40, -5.1714e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6754e-40, -4.9663e-40,  6.1840e-40],\n",
      "          [-5.0772e-40,  5.9414e-40,  5.2475e-40],\n",
      "          [-3.9004e-40, -6.0106e-40,  1.1628e-40]],\n",
      "\n",
      "         [[-5.0261e-40,  6.0189e-40,  1.2644e-41],\n",
      "          [-4.4690e-40,  5.2943e-40,  2.7115e-41],\n",
      "          [ 4.9552e-40, -5.8733e-40,  4.9588e-41]],\n",
      "\n",
      "         [[-6.0346e-40,  5.7437e-40, -5.8068e-40],\n",
      "          [ 1.4655e-40,  3.8255e-43,  4.4015e-41],\n",
      "          [ 5.9199e-40,  6.1854e-40, -3.4745e-40]]],\n",
      "\n",
      "\n",
      "        [[[-5.0803e-40, -5.1391e-40, -5.2483e-40],\n",
      "          [ 3.2983e-40, -4.2668e-40,  1.2810e-40],\n",
      "          [-5.5472e-40,  2.0618e-40,  5.8698e-40]],\n",
      "\n",
      "         [[-5.2881e-40, -5.3971e-40,  5.3268e-41],\n",
      "          [-1.6322e-40,  3.6682e-41, -4.9455e-40],\n",
      "          [-5.6987e-40, -5.4442e-40,  6.0205e-40]],\n",
      "\n",
      "         [[-2.5871e-41, -5.7474e-40,  5.8596e-40],\n",
      "          [ 4.1934e-41, -5.2923e-41, -4.4958e-40],\n",
      "          [-1.9122e-40,  4.9760e-40, -1.1336e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5480e-41, -6.2020e-40,  5.2233e-41],\n",
      "          [ 6.1842e-40,  5.5507e-40,  3.5823e-40],\n",
      "          [ 4.9604e-40, -4.7254e-40,  1.6187e-40]],\n",
      "\n",
      "         [[-3.5449e-40,  5.1122e-40, -5.0246e-40],\n",
      "          [ 4.9884e-40,  4.9449e-40, -5.7144e-40],\n",
      "          [-5.3891e-40,  5.8367e-40,  4.9288e-40]],\n",
      "\n",
      "         [[ 3.4814e-40, -6.0639e-40,  5.9913e-40],\n",
      "          [-1.0770e-41,  4.4760e-40, -5.4068e-40],\n",
      "          [ 5.2664e-40,  3.4350e-40, -2.5166e-41]]]], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "features.8.bias : torch.Size([256])\n",
      "Parameter containing:\n",
      "tensor([-4.0670e-40,  8.7203e-42,  5.5578e-40, -1.6043e-41,  1.3039e-39,\n",
      "         3.1376e-41,  2.4765e-41, -5.5947e-40,  1.0600e-40,  1.9701e-40,\n",
      "        -5.2357e-40, -4.3873e-40, -3.4377e-40, -1.2319e-41, -2.2529e-40,\n",
      "        -2.1140e-41, -1.4693e-39,  4.7621e-40, -4.8217e-40, -7.5852e-42,\n",
      "         2.9438e-40, -5.2763e-40, -6.0637e-40, -5.6532e-40, -2.4475e-40,\n",
      "        -5.0735e-40, -3.1242e-40, -5.1856e-41, -2.4291e-40, -3.2376e-41,\n",
      "        -6.1044e-40,  4.6469e-40,  5.2266e-40,  1.6766e-39, -5.4584e-40,\n",
      "        -4.5721e-40,  5.7527e-40, -1.7916e-40,  1.3817e-40, -1.1999e-39,\n",
      "        -2.1921e-40,  5.4097e-40, -4.0347e-40, -1.0207e-41,  5.0264e-40,\n",
      "        -3.3037e-40, -5.4428e-40, -1.7915e-40, -1.4344e-40, -5.1318e-40,\n",
      "        -6.0103e-40, -5.3946e-40, -4.4086e-41,  4.8813e-40, -1.5318e-40,\n",
      "        -5.8559e-40, -4.5542e-40,  4.8780e-40, -3.6221e-40, -3.7190e-40,\n",
      "         5.8778e-40,  5.7651e-40, -2.4913e-40, -4.9080e-40,  5.8765e-40,\n",
      "         4.6128e-40,  6.2034e-41, -5.7276e-40, -3.6097e-40, -5.3109e-40,\n",
      "        -5.7015e-40, -2.9124e-38,  1.3731e-41,  3.1952e-40, -6.1383e-40,\n",
      "        -3.7410e-40, -1.5050e-40, -1.7143e-40,  4.9615e-40,  5.4021e-40,\n",
      "        -1.1265e-40, -5.9232e-40, -3.2920e-40, -6.0241e-40, -1.1024e-40,\n",
      "        -4.4223e-40,  5.2656e-40,  5.0360e-40, -5.7790e-42,  1.9262e-40,\n",
      "         5.4473e-40, -5.4812e-40, -3.2143e-40, -5.1652e-40, -5.8891e-40,\n",
      "        -9.6437e-42, -4.6767e-40, -2.3418e-41, -5.8136e-40, -5.8248e-40,\n",
      "        -2.3115e-40,  3.7262e-40,  6.0732e-40, -4.9404e-40,  3.5445e-40,\n",
      "         2.0850e-40,  2.0677e-40, -3.0675e-40, -5.8691e-40,  1.0750e-38,\n",
      "         3.5639e-40, -5.1938e-40, -5.2468e-40, -4.6588e-40,  5.1883e-40,\n",
      "         1.3454e-41,  5.1934e-40,  5.6542e-40, -5.4867e-40,  2.5719e-40,\n",
      "        -5.3900e-40,  3.7271e-40, -4.3669e-40, -5.1678e-40, -1.2110e-41,\n",
      "        -3.2799e-40, -5.6712e-40, -1.5724e-39, -4.6461e-40, -3.2958e-40,\n",
      "        -5.0119e-40, -1.0575e-40,  4.9289e-40, -3.2845e-41, -5.0937e-40,\n",
      "        -5.1939e-40, -5.8195e-40, -5.3517e-40, -9.6025e-40, -4.9988e-40,\n",
      "        -2.3962e-42,  6.1150e-40, -5.0924e-40,  5.2116e-40, -5.1362e-40,\n",
      "         9.0566e-42, -6.1382e-40, -1.0942e-40, -5.4559e-40, -4.6429e-40,\n",
      "         5.5709e-40,  5.3332e-40,  4.6993e-40,  1.2403e-41, -4.6772e-40,\n",
      "         4.9466e-40, -5.0320e-40,  5.0620e-40,  5.1446e-40,  5.4873e-41,\n",
      "         5.1810e-40,  4.5293e-40, -3.5505e-40,  5.6172e-40,  5.6588e-40,\n",
      "        -5.1871e-40, -1.4828e-40, -5.4541e-40,  4.7154e-40,  3.4960e-41,\n",
      "         5.6005e-40, -5.4073e-40, -1.7392e-40,  5.7146e-40, -2.9532e-41,\n",
      "         5.4196e-40, -5.4686e-40, -2.0079e-40, -5.8157e-40, -5.4008e-40,\n",
      "        -5.5896e-40,  3.5510e-41,  5.5536e-40, -4.6529e-40, -3.3071e-42,\n",
      "        -4.9094e-41,  5.6456e-40, -2.9862e-40,  1.5075e-40,  4.1329e-40,\n",
      "        -4.4602e-40,  5.0998e-40, -1.3696e-40, -5.7439e-40, -2.7862e-40,\n",
      "         4.6728e-40, -5.8433e-40, -2.9829e-40,  4.9499e-40, -4.3651e-40,\n",
      "         4.6543e-40, -6.1001e-40, -5.5814e-40,  2.9379e-40,  5.7465e-40,\n",
      "        -5.5545e-40,  5.4171e-40,  1.2217e-40,  2.3458e-42,  5.0995e-40,\n",
      "         2.1473e-40,  6.1441e-41, -6.1230e-40,  5.0744e-40,  1.0580e-40,\n",
      "        -6.5532e-41, -5.6690e-40,  3.4667e-40,  6.1844e-41,  5.2538e-40,\n",
      "         1.3923e-41,  6.0511e-40,  2.4717e-40,  3.8790e-40,  5.7653e-40,\n",
      "         3.9941e-40, -5.0309e-40,  5.4686e-40, -5.7730e-40,  5.8818e-40,\n",
      "        -4.9137e-40, -4.1480e-41, -4.4371e-40,  5.9978e-40, -3.2069e-40,\n",
      "        -5.0628e-40, -5.3235e-40, -1.6393e-40, -6.0358e-41, -2.2439e-41,\n",
      "         2.0671e-40, -2.2815e-40,  5.6570e-42, -7.8951e-40,  5.5431e-40,\n",
      "         5.5670e-40,  5.7848e-39,  3.3598e-40, -5.5844e-40,  3.6452e-40,\n",
      "        -5.9506e-40,  1.2370e-40, -3.6100e-40,  1.8185e-40,  5.9649e-40,\n",
      "        -5.9124e-40], device='cuda:1', requires_grad=True)\n",
      "features.11.weight : torch.Size([512, 256, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([[[[ 5.9742e-40, -5.4268e-40, -1.7467e-40],\n",
      "          [-5.1129e-41, -5.0090e-40,  5.9056e-41],\n",
      "          [ 1.6829e-40,  5.2527e-40, -6.0149e-40]],\n",
      "\n",
      "         [[-4.7008e-41,  6.1125e-42,  5.3559e-41],\n",
      "          [-1.8124e-40, -1.1920e-40,  5.9852e-40],\n",
      "          [-5.1580e-40, -4.3004e-41, -4.9637e-40]],\n",
      "\n",
      "         [[-2.7734e-41, -4.1854e-40,  5.9160e-40],\n",
      "          [-5.1405e-41, -6.5680e-41, -5.9055e-40],\n",
      "          [ 5.2013e-40, -3.5826e-40, -6.1616e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.0364e-41,  5.4076e-41,  2.0777e-40],\n",
      "          [-5.5348e-40, -2.6965e-41, -5.4434e-40],\n",
      "          [ 5.7036e-40, -6.1590e-40, -6.3735e-41]],\n",
      "\n",
      "         [[ 5.3128e-40, -5.3713e-40,  3.6064e-40],\n",
      "          [ 5.4824e-40,  5.1068e-41, -6.1655e-40],\n",
      "          [-4.6340e-41,  3.6736e-40, -3.6030e-40]],\n",
      "\n",
      "         [[ 2.8420e-40, -6.1188e-40, -7.9833e-41],\n",
      "          [ 2.5591e-41, -2.8685e-41,  5.0413e-40],\n",
      "          [ 6.1001e-40,  1.7008e-40, -6.0700e-40]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5822e-40,  5.3110e-40, -4.8638e-40],\n",
      "          [-1.1980e-41, -4.0186e-41,  4.5991e-42],\n",
      "          [-5.5621e-40, -1.1974e-40, -5.4197e-40]],\n",
      "\n",
      "         [[-5.1655e-40,  4.8587e-41, -5.6383e-40],\n",
      "          [-5.8324e-40, -5.5361e-40, -5.5053e-40],\n",
      "          [-5.4820e-40,  2.1135e-40,  5.8860e-40]],\n",
      "\n",
      "         [[-5.6011e-40, -5.6012e-40,  3.9401e-40],\n",
      "          [-5.7855e-40, -2.1596e-40,  2.8408e-40],\n",
      "          [-3.3478e-41, -6.5301e-42,  5.2445e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0891e-40, -5.8115e-40, -5.7136e-40],\n",
      "          [ 5.3279e-40,  2.4164e-41,  5.3417e-41],\n",
      "          [ 4.9867e-41, -5.0328e-40,  5.8875e-40]],\n",
      "\n",
      "         [[ 5.0733e-40,  4.9941e-40,  6.1738e-40],\n",
      "          [ 5.4931e-40,  6.0244e-40, -5.1354e-40],\n",
      "          [ 5.6966e-41,  6.0870e-40, -6.3238e-41]],\n",
      "\n",
      "         [[-5.4873e-40, -2.1009e-40,  2.2541e-41],\n",
      "          [ 5.9829e-40,  5.4848e-40,  1.0070e-40],\n",
      "          [ 5.7711e-40, -4.8958e-40, -5.8276e-41]]],\n",
      "\n",
      "\n",
      "        [[[-3.3422e-40, -5.5701e-40, -1.7568e-41],\n",
      "          [ 5.4743e-40,  5.5314e-40, -5.9274e-40],\n",
      "          [ 6.2065e-40,  4.2507e-40,  5.6529e-40]],\n",
      "\n",
      "         [[ 6.1913e-40,  4.7054e-40,  4.3552e-40],\n",
      "          [-5.1461e-40, -3.2401e-40, -5.5609e-40],\n",
      "          [-4.9270e-40,  5.6017e-41,  2.1907e-40]],\n",
      "\n",
      "         [[ 4.0660e-41,  2.2793e-40,  4.2630e-40],\n",
      "          [ 4.9273e-40, -5.0342e-40,  5.7529e-40],\n",
      "          [-6.0640e-40,  3.4814e-40, -4.4315e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.0585e-40,  5.1272e-40, -4.3366e-40],\n",
      "          [-2.4910e-40,  4.0392e-40,  5.5116e-40],\n",
      "          [-1.6192e-41, -5.8066e-40, -2.1462e-40]],\n",
      "\n",
      "         [[ 5.9014e-40, -5.9586e-40, -5.2500e-40],\n",
      "          [-5.5884e-42, -4.9727e-40, -3.9801e-40],\n",
      "          [ 5.7558e-40,  5.1267e-40, -2.0434e-41]],\n",
      "\n",
      "         [[ 4.4340e-40, -5.7018e-40,  5.5189e-40],\n",
      "          [ 4.4667e-40, -5.9659e-40, -3.3815e-41],\n",
      "          [ 2.2677e-40, -2.0826e-40, -1.7527e-40]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.9169e-41, -5.2449e-40,  2.9633e-41],\n",
      "          [-2.2209e-40,  5.2175e-40, -4.9061e-40],\n",
      "          [-4.9915e-40, -1.2926e-40,  5.8424e-40]],\n",
      "\n",
      "         [[-6.1696e-40, -6.1897e-40,  9.1379e-42],\n",
      "          [ 5.4090e-40,  3.7853e-40, -4.4931e-40],\n",
      "          [ 5.0618e-40,  3.9741e-40,  6.0230e-40]],\n",
      "\n",
      "         [[-6.1484e-40, -5.1013e-40, -5.7927e-40],\n",
      "          [ 5.7974e-40, -5.0502e-40,  2.4347e-40],\n",
      "          [ 4.1326e-41,  2.3608e-40, -5.2100e-42]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.5410e-40, -6.0581e-40,  4.9688e-40],\n",
      "          [-6.0167e-40, -1.4020e-40, -6.6520e-42],\n",
      "          [ 4.9395e-40, -5.1708e-40,  4.8263e-40]],\n",
      "\n",
      "         [[-5.6016e-40, -2.6228e-41, -4.3747e-41],\n",
      "          [-5.9515e-41,  5.9107e-40, -5.5268e-40],\n",
      "          [ 8.6299e-41,  6.1156e-40, -5.8822e-40]],\n",
      "\n",
      "         [[-5.4898e-40, -3.0565e-40,  4.9967e-40],\n",
      "          [-5.0654e-40, -5.2692e-40,  5.2800e-40],\n",
      "          [ 5.0245e-40,  5.2551e-41, -7.8893e-43]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2295e-42, -4.3369e-41, -5.6568e-40],\n",
      "          [ 3.5718e-41, -3.8583e-41, -2.2619e-40],\n",
      "          [-1.5795e-41, -5.7949e-41,  5.0365e-41]],\n",
      "\n",
      "         [[ 5.3213e-40,  5.0801e-40, -4.9510e-40],\n",
      "          [ 4.9250e-40, -8.9439e-41, -4.1173e-40],\n",
      "          [ 5.5782e-40,  5.8738e-40, -5.7095e-40]],\n",
      "\n",
      "         [[ 1.6748e-40, -6.5494e-41, -4.0000e-40],\n",
      "          [-6.1613e-40, -6.0959e-40, -5.5891e-40],\n",
      "          [ 3.9758e-41, -2.6304e-41, -5.4985e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0854e-40,  5.8397e-40, -1.4213e-40],\n",
      "          [ 5.5999e-40,  2.2087e-41,  5.9896e-40],\n",
      "          [-4.9686e-40,  4.8610e-40,  1.8563e-40]],\n",
      "\n",
      "         [[ 4.0945e-40, -4.8650e-40, -5.7675e-40],\n",
      "          [-5.7911e-40,  2.9438e-41,  9.7616e-41],\n",
      "          [ 5.2511e-40,  6.1169e-41, -4.9586e-40]],\n",
      "\n",
      "         [[-6.0435e-40, -5.1893e-40,  6.1591e-40],\n",
      "          [-3.6301e-41, -3.8616e-40,  6.1682e-41],\n",
      "          [-5.4322e-40,  4.2737e-40, -5.4222e-40]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6709e-42,  1.5425e-41,  2.0902e-40],\n",
      "          [-4.9211e-40,  5.5888e-40,  5.1195e-41],\n",
      "          [ 5.2084e-40,  3.1418e-40, -4.9484e-40]],\n",
      "\n",
      "         [[ 6.0568e-40,  3.3565e-40, -5.4175e-40],\n",
      "          [ 2.6702e-41,  5.5057e-41,  4.3491e-40],\n",
      "          [-1.1123e-40,  4.9747e-40,  5.3658e-40]],\n",
      "\n",
      "         [[ 8.9543e-42,  5.6844e-40, -6.1731e-40],\n",
      "          [-6.1763e-40, -5.5325e-41, -1.1087e-40],\n",
      "          [-5.1303e-40, -5.0794e-40, -7.0037e-42]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.9684e-40, -6.8930e-41, -6.1134e-40],\n",
      "          [ 6.0581e-40,  2.0230e-40, -5.2688e-40],\n",
      "          [ 5.4177e-40, -3.5090e-40,  1.8108e-40]],\n",
      "\n",
      "         [[ 5.0686e-40, -3.0602e-41, -3.0386e-41],\n",
      "          [-6.1281e-40, -4.6899e-41,  5.3100e-40],\n",
      "          [ 3.8883e-41,  1.8769e-40,  6.1411e-40]],\n",
      "\n",
      "         [[ 2.6319e-41, -5.2360e-40,  5.2633e-40],\n",
      "          [ 5.4271e-40,  5.2349e-40, -5.9242e-40],\n",
      "          [ 3.1333e-42,  5.2182e-40,  6.0113e-40]]]], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "features.11.bias : torch.Size([512])\n",
      "Parameter containing:\n",
      "tensor([-5.5835e-40, -3.1265e-38,  1.3465e-40, -1.8538e-39,  1.0828e-40,\n",
      "        -5.4350e-40,  1.5147e-40, -1.0224e-40, -5.7464e-40, -4.9143e-40,\n",
      "         1.7106e-41, -5.4942e-40, -3.7009e-39, -5.2790e-40, -5.2135e-41,\n",
      "         5.7508e-40,  6.0167e-39,  6.0882e-40, -5.3735e-40,  2.9792e-40,\n",
      "        -7.2843e-40, -4.3464e-41,  1.6707e-40,  5.7683e-40, -4.0494e-40,\n",
      "        -5.7479e-39, -5.1789e-40, -5.4998e-40,  2.8956e-40, -4.8946e-40,\n",
      "         2.7804e-39, -5.3615e-40,  9.1027e-41, -3.3983e-40,  7.8553e-41,\n",
      "        -5.0893e-40, -8.5454e-41,  5.3831e-40,  5.8954e-41,  7.6444e-40,\n",
      "         4.7072e-40, -2.1922e-39, -4.8418e-41, -3.5375e-39, -5.6813e-40,\n",
      "         2.1719e-40, -4.5454e-38,  1.1191e-39,  5.1472e-40, -5.8898e-40,\n",
      "        -1.7272e-39,  5.3322e-40, -4.1107e-41, -4.9292e-40, -4.9841e-40,\n",
      "         5.5758e-39, -5.0058e-40,  2.0979e-40, -9.3935e-40,  5.2733e-40,\n",
      "        -5.4849e-40,  2.6839e-41, -5.5381e-40, -2.8843e-40,  5.3715e-40,\n",
      "        -6.0559e-40, -4.8385e-41, -4.7409e-40, -5.1713e-40, -1.8120e-40,\n",
      "         5.9635e-40,  9.3747e-42,  2.2249e-39, -1.9199e-40, -1.9050e-40,\n",
      "         4.1797e-40,  4.9788e-40,  5.2445e-40, -5.3099e-40,  5.5329e-40,\n",
      "        -4.7048e-40,  1.0737e-41, -3.9913e-40,  5.2208e-40, -5.8014e-40,\n",
      "         5.5779e-40, -5.3398e-40, -1.8702e-40, -5.4109e-40, -5.6735e-40,\n",
      "         3.1129e-40,  2.5993e-40, -5.3809e-40,  5.5891e-40, -5.3363e-40,\n",
      "        -5.3805e-40, -2.3642e-39, -5.4296e-40, -2.5980e-40, -3.1612e-40,\n",
      "         4.7225e-40,  2.5323e-41, -3.6088e-39,  5.5336e-40, -6.2015e-40,\n",
      "        -5.5330e-40, -4.7184e-40, -2.1787e-41, -7.8012e-41,  9.6402e-41,\n",
      "         2.2232e-40,  5.9248e-41, -2.5828e-40, -2.5036e-39, -5.4618e-40,\n",
      "        -4.5444e-41,  4.8134e-38, -1.2661e-40,  3.4753e-40, -1.2691e-37,\n",
      "        -3.3869e-40,  5.4869e-40, -5.5066e-39, -3.6844e-40,  1.2464e-39,\n",
      "         1.1702e-41,  5.7380e-41, -5.1947e-40,  3.1354e-41, -6.0641e-40,\n",
      "        -5.1324e-40,  5.7160e-40,  5.3546e-40,  4.7103e-40,  4.2759e-41,\n",
      "        -1.6645e-38, -5.2942e-40, -1.3906e-39,  5.6401e-40,  4.8098e-40,\n",
      "        -4.6218e-39,  2.1408e-41,  4.2894e-40,  1.4730e-38, -5.8391e-40,\n",
      "         5.6493e-40,  6.1425e-40, -1.1493e-40,  2.1710e-39,  7.3904e-41,\n",
      "        -5.7228e-40,  4.8781e-40,  3.6283e-40,  2.1312e-40,  5.7594e-40,\n",
      "         2.3402e-41,  1.1176e-40,  1.2040e-37, -1.5689e-41,  5.8895e-40,\n",
      "        -1.5967e-38, -5.7883e-40,  7.6041e-40,  9.4823e-41, -3.6257e-39,\n",
      "        -2.1033e-40, -2.0142e-40,  1.9777e-40,  1.2146e-40, -1.7296e-40,\n",
      "        -2.9997e-40, -5.6739e-40, -4.7020e-40, -5.6873e-40,  1.8637e-40,\n",
      "         2.9914e-41, -5.6402e-40, -1.6615e-41, -4.9788e-42, -1.8810e-40,\n",
      "         1.7043e-39, -5.1267e-40, -2.3253e-40,  5.8145e-40, -5.5011e-40,\n",
      "        -1.9722e-39, -5.7820e-40, -5.9331e-40,  5.5639e-40,  4.8793e-40,\n",
      "         2.2043e-40, -7.2573e-39,  7.6775e-40, -5.0065e-40, -1.3396e-38,\n",
      "        -3.4438e-40, -4.3450e-40,  2.7737e-41,  5.2237e-40,  3.3318e-40,\n",
      "        -2.4889e-40,  2.0985e-39, -3.8852e-39,  2.2233e-40,  1.7635e-40,\n",
      "         8.2478e-38,  4.7285e-40, -3.5854e-40, -2.1259e-40, -5.9216e-41,\n",
      "         5.7596e-40, -5.1121e-40, -4.1170e-41, -4.9118e-40,  1.2636e-38,\n",
      "        -5.1753e-40, -2.1764e-38, -1.7955e-41, -2.9877e-40, -1.4810e-39,\n",
      "         4.8277e-40,  5.1110e-40, -1.4193e-38,  2.6089e-40, -1.7399e-40,\n",
      "        -2.9186e-40,  1.8406e-40, -8.1141e-40, -2.4590e-39,  5.4816e-40,\n",
      "        -8.5004e-40, -6.0416e-40, -1.4910e-39,  2.8487e-40,  5.4908e-40,\n",
      "        -1.0879e-40,  5.6626e-40,  5.7866e-40,  5.5206e-40, -5.7809e-40,\n",
      "        -7.1117e-41, -2.1093e-39,  3.3947e-39,  2.1669e-39, -5.8552e-40,\n",
      "         1.2813e-40,  5.3657e-40,  2.4317e-39,  6.5876e-41,  8.8093e-39,\n",
      "        -6.0500e-40, -2.8990e-41, -8.1612e-41, -2.0139e-40, -2.8831e-38,\n",
      "        -4.9476e-40,  4.7317e-38, -1.3778e-40, -4.0079e-40,  6.0258e-40,\n",
      "         1.1371e-40,  5.3974e-40, -5.2335e-40, -5.1574e-40,  5.7334e-40,\n",
      "         5.3516e-41, -5.5674e-42,  5.7968e-40, -2.1274e-40,  3.5638e-39,\n",
      "        -8.8464e-41, -1.3388e-40,  5.1816e-40,  4.1846e-40,  1.3269e-41,\n",
      "        -5.0975e-40,  1.7979e-38, -4.9904e-40,  1.0691e-39,  6.0349e-40,\n",
      "        -2.5525e-40,  6.6944e-39,  6.1682e-40, -1.2930e-38,  3.5375e-40,\n",
      "         2.0073e-40, -6.9865e-41,  4.0693e-40, -1.4097e-40,  6.2163e-41,\n",
      "         5.1949e-40, -1.1070e-38, -5.7801e-40, -5.7755e-40, -5.8218e-40,\n",
      "        -1.7200e-40, -5.9320e-40,  5.7311e-40, -9.4205e-41, -3.3296e-38,\n",
      "         3.3735e-41,  4.1394e-39,  5.3669e-40, -9.2598e-42,  5.2975e-40,\n",
      "        -4.6912e-40,  9.9408e-39, -3.6001e-40,  5.1182e-40, -1.9732e-41,\n",
      "         2.1172e-40,  4.7467e-40, -3.7857e-40, -4.9152e-40, -2.7783e-40,\n",
      "         8.4755e-41, -1.7867e-42,  1.6838e-38, -9.7045e-40,  1.2229e-40,\n",
      "        -4.6469e-40,  7.7536e-39, -4.4039e-40, -3.0089e-40,  5.6969e-40,\n",
      "         1.0496e-39,  4.0375e-40, -2.6436e-40,  8.0556e-39,  3.8187e-40,\n",
      "         3.3598e-40,  4.5335e-40,  5.2942e-40,  1.1757e-41,  4.7358e-40,\n",
      "         1.1226e-40,  3.4424e-38,  1.4635e-36,  1.2800e-39, -5.5141e-38,\n",
      "         2.5421e-41,  2.9752e-40, -5.6752e-40, -7.1305e-41,  3.5833e-40,\n",
      "        -1.3565e-37, -5.7472e-40,  5.7748e-40,  4.9483e-41, -5.2533e-40,\n",
      "         5.5521e-41,  1.3751e-38, -7.1354e-41, -1.0770e-40, -1.3472e-39,\n",
      "         1.0751e-40,  4.2397e-40,  3.6672e-41, -8.5545e-39,  2.6372e-41,\n",
      "         4.9723e-40, -3.1599e-40,  5.7114e-40, -4.6898e-40, -8.8759e-40,\n",
      "        -5.2527e-40,  2.0077e-40,  5.9684e-40, -5.2040e-40,  5.5191e-40,\n",
      "         5.0829e-40,  5.9326e-40,  3.9267e-40, -5.3585e-40, -5.5684e-40,\n",
      "        -3.2540e-40,  5.1736e-41, -5.1762e-39, -5.8274e-40,  4.8454e-40,\n",
      "         5.8199e-40, -8.0116e-41, -1.5208e-38, -5.3941e-40, -2.6478e-40,\n",
      "         5.4056e-40, -1.4832e-39, -5.8427e-40, -5.7268e-40,  4.4671e-40,\n",
      "         1.8019e-41,  1.6721e-40,  4.7951e-40,  2.7815e-38,  8.9611e-39,\n",
      "        -3.0162e-41, -3.8228e-40, -2.7726e-40,  8.7875e-42,  1.7550e-41,\n",
      "         5.7453e-44,  5.3947e-40,  4.6249e-40, -2.6683e-40, -4.6933e-40,\n",
      "        -5.8422e-41,  5.5313e-40, -4.6348e-40,  1.6333e-40,  3.6179e-40,\n",
      "         3.1780e-39, -5.3101e-40,  1.5757e-39, -6.4628e-42, -5.7070e-40,\n",
      "        -4.0049e-42, -3.8623e-39,  1.3913e-38, -4.9433e-40, -3.1177e-40,\n",
      "         5.2318e-40,  4.4991e-38,  9.2130e-40, -4.7711e-40, -6.0582e-40,\n",
      "         4.2416e-39,  5.3216e-40,  6.0255e-40,  2.9861e-40,  2.3731e-40,\n",
      "        -5.3419e-40,  5.8818e-40,  5.0796e-40,  5.9752e-40,  3.3750e-40,\n",
      "        -5.3321e-40,  5.9786e-40, -2.1019e-40,  4.8412e-41,  1.2644e-41,\n",
      "         1.7382e-41,  6.0725e-40,  3.5150e-40, -2.7911e-40, -4.9544e-40,\n",
      "        -5.1790e-40, -2.1141e-40,  1.6082e-40,  4.0498e-42,  1.6782e-40,\n",
      "         4.0862e-41,  5.4410e-40,  5.5455e-40,  5.6426e-40,  4.9384e-40,\n",
      "        -2.8069e-40,  4.6688e-40, -6.0967e-40, -1.0675e-39,  5.2974e-40,\n",
      "        -5.9653e-39, -2.9718e-40,  1.5450e-40,  2.2168e-40,  1.8592e-40,\n",
      "        -1.3995e-40, -4.2011e-42,  5.9499e-40, -4.6887e-40,  8.9081e-42,\n",
      "        -2.7672e-40, -1.8415e-39, -2.2833e-41, -3.2228e-40,  7.1835e-40,\n",
      "        -1.0477e-39, -5.4454e-40, -2.1059e-39,  3.4442e-38,  2.3463e-40,\n",
      "        -5.7001e-40,  5.4275e-40,  2.9225e-40, -5.3952e-40, -1.7002e-38,\n",
      "        -4.3455e-40,  4.9973e-40,  5.3914e-40,  4.7574e-40,  6.9265e-40,\n",
      "        -1.6338e-40, -4.3060e-39, -1.1123e-40, -3.9805e-39, -1.2644e-40,\n",
      "        -9.4899e-41, -4.9452e-40, -5.5931e-40, -5.2192e-40,  5.7239e-40,\n",
      "        -4.8674e-40,  2.6324e-39,  1.3369e-40, -1.5204e-42, -3.4051e-40,\n",
      "         5.0177e-40,  1.9259e-40, -2.3375e-40, -5.1933e-40,  5.5109e-39,\n",
      "        -6.0926e-40, -3.5391e-40], device='cuda:1', requires_grad=True)\n",
      "features.13.weight : torch.Size([512, 512, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([[[[ 4.3556e-40,  3.3600e-41,  6.2252e-40],\n",
      "          [-6.5982e-41,  1.2803e-40,  6.0596e-41],\n",
      "          [ 4.8309e-40,  5.2905e-40, -5.7229e-40]],\n",
      "\n",
      "         [[ 2.7510e-41,  4.9211e-40, -6.2046e-40],\n",
      "          [ 1.1568e-41, -5.8663e-40,  5.1538e-40],\n",
      "          [ 6.2073e-40, -1.4303e-40, -1.4142e-40]],\n",
      "\n",
      "         [[-1.5462e-40,  5.8304e-40, -1.4417e-40],\n",
      "          [-5.0075e-40,  1.4067e-40, -5.1009e-40],\n",
      "          [-3.5029e-40, -5.6332e-40, -8.3684e-41]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.5554e-40, -5.0990e-40,  1.4693e-40],\n",
      "          [ 5.5557e-40,  5.5428e-40,  5.2260e-40],\n",
      "          [-5.9726e-40,  3.9863e-41,  4.8935e-40]],\n",
      "\n",
      "         [[-6.0151e-41,  2.7447e-41, -1.1335e-40],\n",
      "          [ 6.0633e-40,  4.6229e-42, -3.7237e-41],\n",
      "          [ 5.3605e-40, -1.4755e-40, -2.1578e-40]],\n",
      "\n",
      "         [[-1.3141e-40, -3.4808e-40,  2.8718e-41],\n",
      "          [ 3.3700e-41,  6.1868e-40,  5.6335e-40],\n",
      "          [-3.5442e-41,  6.1833e-40, -4.1129e-40]]],\n",
      "\n",
      "\n",
      "        [[[-1.5283e-40,  3.3345e-41, -1.2484e-40],\n",
      "          [-6.0364e-40, -6.1464e-40, -5.4814e-40],\n",
      "          [ 2.7940e-41,  2.5448e-42, -4.1815e-42]],\n",
      "\n",
      "         [[ 9.5874e-41,  4.9747e-40,  5.3792e-40],\n",
      "          [-1.2290e-40,  6.0545e-40,  5.8833e-40],\n",
      "          [ 5.1138e-41,  6.1987e-40, -1.1949e-41]],\n",
      "\n",
      "         [[ 2.1390e-40, -3.3345e-40,  5.2818e-40],\n",
      "          [-5.1677e-40,  5.4717e-40, -4.3624e-40],\n",
      "          [ 5.5811e-40,  5.0933e-40, -5.6378e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.5513e-40,  1.3951e-41,  5.1392e-40],\n",
      "          [ 4.0976e-40, -5.3665e-40, -6.0256e-42],\n",
      "          [-5.3699e-40, -4.9542e-40, -5.0579e-40]],\n",
      "\n",
      "         [[-4.4753e-40,  5.6387e-40,  4.4089e-41],\n",
      "          [-4.0185e-40, -1.6942e-40,  4.8909e-40],\n",
      "          [ 5.5606e-40, -5.7383e-40,  4.8782e-40]],\n",
      "\n",
      "         [[-3.6041e-41,  4.8121e-41,  1.7001e-41],\n",
      "          [ 3.6165e-41,  4.3463e-40, -1.3190e-41],\n",
      "          [ 2.1516e-40, -6.0073e-40,  4.8424e-40]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0081e-40,  5.4384e-40, -3.3001e-40],\n",
      "          [ 6.0251e-40,  4.8248e-40,  5.6647e-40],\n",
      "          [-5.8390e-40,  2.8156e-41, -5.6661e-40]],\n",
      "\n",
      "         [[-5.5858e-40,  1.4397e-40, -3.6424e-40],\n",
      "          [-6.7983e-41,  5.6707e-40,  4.9025e-40],\n",
      "          [ 6.0411e-41,  2.0586e-40,  5.3091e-40]],\n",
      "\n",
      "         [[ 4.9480e-40, -4.9968e-40,  6.3854e-41],\n",
      "          [ 1.5890e-40, -5.3939e-40, -5.4208e-40],\n",
      "          [ 5.2030e-40,  6.1371e-40,  4.0513e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2159e-40, -2.0577e-41, -5.2918e-40],\n",
      "          [ 6.0684e-40,  6.1268e-40,  6.0655e-40],\n",
      "          [ 5.3367e-40, -3.6105e-40,  5.1858e-40]],\n",
      "\n",
      "         [[-4.9068e-40, -5.5484e-40, -5.7125e-40],\n",
      "          [-6.1461e-40,  5.2062e-40,  6.0158e-40],\n",
      "          [-5.5216e-40, -4.8810e-40, -6.1635e-40]],\n",
      "\n",
      "         [[-5.6500e-40, -3.3244e-40, -1.4516e-40],\n",
      "          [ 5.1828e-40,  1.5045e-40, -5.4905e-40],\n",
      "          [-5.3469e-40,  4.7286e-40,  5.5016e-40]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.6109e-41, -3.7749e-40,  6.0682e-41],\n",
      "          [-5.5995e-40, -1.6472e-40,  1.5352e-40],\n",
      "          [-4.0975e-40,  9.0426e-42, -1.0685e-40]],\n",
      "\n",
      "         [[ 5.9827e-40,  4.0610e-42, -5.5079e-40],\n",
      "          [ 5.5085e-42,  5.4861e-40,  5.3981e-40],\n",
      "          [-5.7365e-40,  6.1880e-41,  1.8726e-40]],\n",
      "\n",
      "         [[-4.6831e-42,  3.1535e-41,  5.2179e-40],\n",
      "          [ 5.8700e-40,  5.9559e-40,  4.4640e-40],\n",
      "          [-2.0226e-41,  3.7724e-40,  2.8194e-41]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.8176e-40,  3.0614e-40, -5.5711e-40],\n",
      "          [-5.4014e-40, -7.1965e-41, -5.0140e-40],\n",
      "          [ 5.7072e-40, -4.5465e-40,  5.7891e-40]],\n",
      "\n",
      "         [[ 5.0351e-40, -6.0770e-40, -5.7847e-40],\n",
      "          [-3.4852e-40, -5.1145e-41, -5.3812e-40],\n",
      "          [ 4.8968e-41, -1.7414e-41,  2.3866e-41]],\n",
      "\n",
      "         [[ 6.1042e-40,  5.5775e-40, -5.6044e-40],\n",
      "          [ 5.4476e-40,  5.3757e-40, -4.9719e-40],\n",
      "          [-5.3365e-40, -4.3127e-40, -6.2151e-40]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3338e-41, -5.1894e-40, -6.1429e-40],\n",
      "          [-5.3081e-40, -2.2241e-41, -5.7827e-40],\n",
      "          [ 6.1578e-40, -6.1754e-40, -1.5128e-40]],\n",
      "\n",
      "         [[ 2.3689e-41,  3.3660e-40, -5.3899e-40],\n",
      "          [ 4.0231e-41,  4.1704e-40, -4.1120e-41],\n",
      "          [-4.8785e-40, -5.3358e-40,  9.6517e-41]],\n",
      "\n",
      "         [[ 5.8436e-40, -5.7060e-40,  5.7411e-41],\n",
      "          [-4.8735e-40, -6.1542e-40,  6.1977e-40],\n",
      "          [ 5.3265e-40,  3.3334e-41,  5.4161e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.5972e-41,  6.2051e-41,  5.2734e-40],\n",
      "          [-5.2266e-40, -4.9130e-40, -5.1417e-40],\n",
      "          [-5.4213e-40,  5.6817e-40, -4.3168e-41]],\n",
      "\n",
      "         [[-4.7710e-41, -5.5957e-40, -2.1520e-40],\n",
      "          [ 5.2763e-41, -6.5982e-41,  6.1928e-40],\n",
      "          [-5.7360e-40, -6.0214e-40,  4.4106e-41]],\n",
      "\n",
      "         [[-3.5674e-41,  4.5743e-41,  4.9519e-40],\n",
      "          [ 8.2190e-41, -3.4276e-40,  5.9873e-40],\n",
      "          [-5.8201e-40,  5.4398e-40,  3.4304e-41]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2919e-40, -4.3743e-40, -6.1603e-40],\n",
      "          [-6.1099e-40, -5.0838e-40, -5.9508e-40],\n",
      "          [-6.5806e-41, -4.9387e-40,  3.8444e-40]],\n",
      "\n",
      "         [[-6.3850e-41, -5.9944e-40,  4.8361e-40],\n",
      "          [-6.1113e-40,  6.0555e-40,  5.2234e-40],\n",
      "          [-1.6776e-40, -1.4755e-40, -5.6115e-41]],\n",
      "\n",
      "         [[-2.8623e-41,  2.4984e-41, -6.2027e-41],\n",
      "          [-2.2609e-41,  5.0954e-40, -5.7254e-40],\n",
      "          [ 4.0105e-41, -3.4795e-40, -6.2520e-41]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.1819e-41,  3.4370e-41,  6.0332e-40],\n",
      "          [ 1.8515e-41, -5.2761e-40, -2.4397e-41],\n",
      "          [-4.9191e-40,  6.1020e-40, -4.9276e-40]],\n",
      "\n",
      "         [[-5.8745e-40, -1.4590e-41,  3.8969e-41],\n",
      "          [ 4.9749e-40,  3.3756e-41, -4.9572e-40],\n",
      "          [ 4.9297e-40, -4.3548e-40,  5.5712e-40]],\n",
      "\n",
      "         [[-5.4855e-40,  5.4017e-40,  4.8709e-40],\n",
      "          [-5.4499e-40, -6.1075e-40, -6.2004e-40],\n",
      "          [ 5.1594e-40, -5.4225e-41,  6.1572e-40]]]], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "features.13.bias : torch.Size([512])\n",
      "Parameter containing:\n",
      "tensor([ 4.9766e-40,  2.9073e-39, -3.1213e-40,  9.0769e-37, -5.3782e-40,\n",
      "         1.5842e-39,  3.3472e-34, -4.2608e-38,  9.7960e-40,  3.5039e-40,\n",
      "         5.2683e-40,  2.1470e-39, -3.4254e-40,  3.1660e-38, -1.4901e-38,\n",
      "        -2.9713e-40,  1.7587e-39,  5.7727e-40,  3.7730e-39,  7.1876e-40,\n",
      "        -2.5131e-38,  5.0216e-40,  2.7854e-33,  2.9229e-40, -4.4962e-39,\n",
      "         9.3434e-41, -5.7717e-40, -4.9857e-40,  6.0170e-40,  3.2793e-40,\n",
      "        -1.0055e-39, -5.9681e-39, -5.6834e-40,  2.1532e-40,  8.6257e-41,\n",
      "        -8.6937e-42,  5.3838e-40, -2.2093e-40,  3.8896e-40,  3.0242e-40,\n",
      "        -6.3511e-40, -1.6972e-40,  1.8926e-40, -5.5535e-38,  1.6162e-36,\n",
      "         8.7303e-39,  7.4553e-35,  3.9090e-38,  1.3627e-38,  2.0277e-38,\n",
      "        -4.2246e-39, -4.3492e-39,  4.5895e-38,  7.5783e-40, -4.8035e-40,\n",
      "         5.4664e-40, -4.9588e-39, -1.0156e-40, -5.8980e-40,  2.9244e-37,\n",
      "         1.1359e-37,  4.9823e-40, -8.5553e-35,  4.7756e-42, -1.7775e-40,\n",
      "         1.9016e-37, -3.1907e-39, -5.9429e-40,  5.0901e-40, -3.1904e-37,\n",
      "        -1.8272e-39,  5.4606e-40,  5.0890e-40,  2.1405e-40,  1.2192e-37,\n",
      "        -1.7030e-40, -3.4872e-40, -9.8785e-36, -7.3204e-38, -1.0234e-37,\n",
      "        -4.7879e-39, -1.4747e-40, -2.3392e-39,  1.5370e-39, -6.7856e-40,\n",
      "         6.1439e-40, -5.0046e-40,  5.5436e-40,  2.3576e-38, -7.7759e-36,\n",
      "        -1.1279e-40,  4.6163e-40, -3.2880e-40, -5.0384e-37, -1.8678e-35,\n",
      "         4.0366e-33, -6.0649e-40, -2.9603e-38,  2.6777e-41,  5.5049e-40,\n",
      "         3.1420e-37,  5.9241e-40,  5.6561e-35,  2.1628e-35,  7.8593e-40,\n",
      "         5.9437e-40,  1.4058e-37, -1.7376e-38, -5.6565e-40,  5.5427e-40,\n",
      "         2.2270e-38,  4.5193e-40, -3.6082e-37,  1.6709e-41, -5.5028e-40,\n",
      "        -5.5668e-40, -3.5090e-40, -5.4782e-40, -2.0515e-39, -2.7802e-39,\n",
      "        -6.0675e-40, -9.2206e-39, -7.0189e-39,  3.2058e-40,  2.0495e-39,\n",
      "         4.5822e-40,  2.1303e-41,  6.6080e-35, -1.1408e-37, -2.5215e-40,\n",
      "        -3.4788e-40, -5.5697e-40,  5.7838e-40, -1.2487e-37,  5.1063e-35,\n",
      "         1.9040e-36,  5.0195e-40,  6.1426e-40,  2.6973e-36,  3.4796e-38,\n",
      "         3.4008e-40, -5.8242e-40,  2.5171e-38, -7.0635e-37,  5.0724e-40,\n",
      "        -7.7198e-42, -5.3937e-39, -5.0204e-39,  5.4020e-40, -2.3824e-36,\n",
      "        -3.6490e-39,  3.8361e-38, -2.7593e-36,  3.1032e-41, -1.7927e-40,\n",
      "        -1.3415e-41, -4.0310e-34, -3.6495e-41,  5.9320e-40, -4.4445e-40,\n",
      "        -9.8719e-36, -1.1521e-37, -4.9471e-36, -5.8915e-40,  4.0356e-39,\n",
      "         8.1238e-40,  1.6282e-40,  5.2722e-40, -1.7523e-41, -2.7044e-38,\n",
      "        -2.2638e-40,  1.8833e-36,  4.9817e-40,  5.5045e-40,  5.0436e-40,\n",
      "         2.4780e-33,  5.3763e-40, -1.8374e-40,  5.2747e-40,  4.8043e-40,\n",
      "         5.2884e-40, -6.0580e-35, -6.8296e-37, -1.4169e-37, -1.4994e-37,\n",
      "        -4.8937e-40,  3.3825e-40, -3.0069e-37,  3.5144e-35, -7.3497e-38,\n",
      "        -3.2632e-36,  1.8461e-40,  5.8438e-40, -4.9984e-40,  3.5538e-41,\n",
      "        -3.0746e-37, -5.5931e-40, -1.0251e-40, -4.1728e-35, -5.4030e-40,\n",
      "         5.1445e-38, -1.3011e-39, -1.4972e-36, -2.1153e-40, -5.9071e-40,\n",
      "        -5.6348e-40, -4.2705e-40,  4.1523e-39,  4.8925e-40,  5.8090e-40,\n",
      "         5.0152e-40, -4.9806e-40, -1.9531e-40, -5.7241e-40,  7.6276e-39,\n",
      "         2.4202e-40, -2.0131e-37,  5.6189e-38,  1.7323e-39,  5.5467e-40,\n",
      "         1.2279e-38,  2.6986e-40, -1.0039e-38, -5.6075e-37,  4.5129e-40,\n",
      "        -8.0463e-41,  5.2039e-40, -4.5781e-39,  9.9475e-37, -2.9504e-40,\n",
      "         2.5846e-38, -2.3714e-40, -4.7320e-33,  2.0182e-40,  4.8877e-39,\n",
      "         6.3936e-41,  5.1035e-40,  6.4663e-36, -3.9721e-39, -5.2148e-40,\n",
      "         5.5672e-40,  5.0613e-40, -5.3511e-40,  5.6341e-36,  5.8121e-40,\n",
      "         1.9973e-35, -1.0012e-40,  9.3428e-38, -2.5883e-40,  1.7285e-37,\n",
      "         1.5497e-38,  1.2636e-37,  7.6416e-36,  1.8567e-42, -1.2607e-41,\n",
      "         2.9270e-37, -5.2999e-40, -4.2345e-36,  3.0742e-40, -3.4171e-40,\n",
      "        -5.3825e-40,  9.3626e-35,  5.8823e-35,  3.0841e-40,  6.8015e-35,\n",
      "        -1.8179e-41, -4.6439e-40, -2.0701e-37,  5.0946e-40, -3.9280e-40,\n",
      "        -3.7806e-37,  4.5149e-40, -5.5476e-40,  4.0350e-38,  4.3833e-42,\n",
      "        -1.0429e-40,  1.7130e-39,  2.1630e-41, -5.9490e-40, -4.5932e-40,\n",
      "         2.9450e-40,  5.6865e-40, -5.8086e-40,  2.0229e-40,  3.4055e-40,\n",
      "         5.2593e-40,  1.7799e-41, -1.6938e-35, -5.2712e-40, -1.1906e-39,\n",
      "        -2.1841e-40,  8.3798e-43,  1.7269e-37,  3.9711e-40,  5.3862e-36,\n",
      "        -4.9284e-40, -2.2286e-39,  2.1754e-35,  2.5463e-41, -1.4970e-38,\n",
      "         4.5428e-38, -5.6140e-40, -5.0404e-40,  5.7177e-40, -5.2853e-40,\n",
      "         1.0328e-37, -3.2813e-39,  6.3643e-40, -9.5011e-41, -4.6506e-40,\n",
      "        -1.0589e-40,  5.2759e-40, -5.7133e-40, -3.2742e-40,  1.2851e-41,\n",
      "        -4.3653e-40,  1.6055e-38, -2.0675e-36,  8.3005e-38, -5.1114e-40,\n",
      "         4.4082e-39,  6.2994e-38,  5.4972e-40, -1.2767e-38,  1.0618e-39,\n",
      "         3.0764e-40, -4.9735e-40, -8.2200e-42, -9.5172e-39,  5.4047e-40,\n",
      "        -2.8284e-38, -7.6607e-37, -8.3998e-41,  2.0289e-41, -5.8803e-40,\n",
      "        -5.6337e-40,  1.5614e-37,  1.9835e-36,  1.1593e-41, -5.3344e-40,\n",
      "        -2.5038e-36, -1.1789e-36, -5.9538e-40, -4.9561e-40,  1.2953e-39,\n",
      "        -5.4506e-40,  9.3062e-36, -5.5420e-40,  1.8198e-40, -5.6819e-40,\n",
      "        -1.2774e-40, -5.7566e-40, -4.8276e-40, -5.6257e-40,  5.4633e-40,\n",
      "         5.7968e-40,  8.6313e-36,  1.4536e-38, -3.2088e-40, -8.6416e-38,\n",
      "         4.8648e-40,  3.3201e-35, -3.6102e-39,  5.3537e-40, -5.7181e-39,\n",
      "        -5.9065e-40, -3.1317e-36,  4.9087e-36, -5.1986e-40,  2.8703e-38,\n",
      "        -2.4255e-39,  7.6147e-39, -5.0923e-40,  3.0879e-40,  5.7817e-39,\n",
      "        -4.7864e-40, -1.0619e-38,  6.8089e-38,  3.1236e-35,  2.0707e-36,\n",
      "         2.3627e-38, -5.3075e-40, -5.6309e-38, -5.1420e-37, -1.5392e-34,\n",
      "        -5.7942e-39, -4.5786e-40, -3.8604e-38, -5.6569e-40, -3.9115e-40,\n",
      "        -2.2853e-36, -2.2683e-38,  1.8583e-40,  4.3285e-38, -1.5667e-37,\n",
      "        -4.7850e-40,  2.3710e-41, -1.3044e-39, -7.9664e-41,  4.1484e-36,\n",
      "        -5.7473e-40, -7.2972e-38, -9.9062e-40, -1.0893e-40,  9.1171e-37,\n",
      "         6.0310e-40, -9.7372e-38,  6.0593e-39,  3.0013e-40,  2.5138e-38,\n",
      "        -4.4725e-38,  5.2175e-40,  9.6076e-39, -4.7491e-40,  4.6911e-40,\n",
      "        -3.3333e-40,  5.5288e-40,  2.2051e-40, -5.9262e-38, -8.9729e-36,\n",
      "        -5.2743e-40,  1.9211e-40,  1.6097e-39,  5.6193e-40,  3.4596e-38,\n",
      "        -2.2966e-37, -5.6747e-40,  4.9553e-40,  3.9734e-40,  1.5239e-36,\n",
      "         5.5573e-40, -3.6563e-40, -6.0268e-40, -1.0553e-35, -8.9699e-36,\n",
      "         4.2265e-40, -4.8969e-38, -2.2813e-37,  6.2590e-40, -2.8781e-40,\n",
      "         1.6878e-38, -5.8460e-40, -1.9083e-38,  4.7763e-38, -5.9687e-40,\n",
      "         3.3953e-40, -7.8104e-39,  5.7371e-40,  6.3409e-36, -2.8169e-41,\n",
      "         3.8834e-40, -9.1839e-39,  2.6119e-38,  4.6492e-40, -5.7720e-40,\n",
      "        -3.2599e-38,  2.1773e-40, -6.2901e-40,  5.4394e-39, -5.5300e-40,\n",
      "        -4.0008e-39,  1.0087e-38, -5.7103e-37,  1.2984e-36, -5.2563e-40,\n",
      "        -6.1903e-37, -2.7782e-35,  5.0897e-40, -4.6460e-38,  2.8698e-40,\n",
      "        -3.4019e-40,  5.2648e-40, -2.1564e-40, -9.4293e-38, -2.8166e-41,\n",
      "        -1.6625e-40,  1.8257e-37,  6.0027e-36,  7.4042e-37, -3.0574e-40,\n",
      "         2.3013e-40,  1.1029e-39, -5.1894e-40,  1.1510e-40, -2.0076e-39,\n",
      "        -5.4157e-41,  2.2825e-38,  1.6016e-38, -6.1165e-41, -3.6608e-38,\n",
      "        -5.5622e-37,  2.2141e-43,  3.6413e-41,  4.1776e-39, -3.5942e-41,\n",
      "         1.5124e-36, -2.0074e-41, -1.6100e-35,  2.0953e-40,  6.3589e-38,\n",
      "         9.0179e-41, -8.1395e-39, -3.4109e-39,  3.1906e-40, -6.1457e-39,\n",
      "        -2.4423e-40,  1.4649e-40, -5.9336e-40, -7.2767e-41, -2.8469e-40,\n",
      "         5.5517e-40,  2.8757e-40], device='cuda:1', requires_grad=True)\n",
      "features.16.weight : torch.Size([512, 512, 3, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-3.4137e-40, -6.2210e-40, -1.9191e-40],\n",
      "          [-5.9289e-40,  6.5246e-41,  4.1840e-41],\n",
      "          [ 5.2780e-40,  2.1351e-40,  6.0395e-40]],\n",
      "\n",
      "         [[ 3.8129e-41,  6.2396e-41,  4.8332e-41],\n",
      "          [ 4.9322e-40, -1.4336e-40, -5.9626e-40],\n",
      "          [ 6.0671e-40, -5.7222e-40,  5.7514e-40]],\n",
      "\n",
      "         [[ 4.9902e-40,  2.2028e-41, -4.8677e-40],\n",
      "          [-1.4679e-40,  5.1729e-40, -3.5207e-40],\n",
      "          [ 5.1241e-40,  1.4426e-41,  1.1763e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8623e-42,  2.0780e-40, -9.0818e-42],\n",
      "          [-5.9213e-40,  5.6818e-40, -5.5821e-40],\n",
      "          [ 6.1137e-40,  1.9603e-41, -4.6215e-40]],\n",
      "\n",
      "         [[-1.6736e-40, -5.2834e-40,  1.4320e-41],\n",
      "          [ 4.3676e-40, -2.6982e-41, -1.4257e-40],\n",
      "          [-4.9753e-40, -6.1088e-40, -3.3540e-40]],\n",
      "\n",
      "         [[ 9.1412e-41, -3.1248e-40, -2.0072e-41],\n",
      "          [ 5.2271e-40, -3.4805e-40, -4.9176e-40],\n",
      "          [ 3.6703e-41, -5.5927e-40,  2.4701e-41]]],\n",
      "\n",
      "\n",
      "        [[[-4.1902e-41,  3.1609e-40,  1.8339e-40],\n",
      "          [ 5.7343e-40,  9.2486e-42, -5.1709e-40],\n",
      "          [ 4.8991e-41,  5.8356e-40,  5.2640e-40]],\n",
      "\n",
      "         [[-1.0082e-40,  5.8670e-40, -5.1637e-40],\n",
      "          [-6.1199e-41, -1.1769e-40, -3.8272e-40],\n",
      "          [-2.7784e-41, -5.3462e-41, -5.4247e-40]],\n",
      "\n",
      "         [[-5.1220e-40,  5.9179e-40, -7.1326e-43],\n",
      "          [ 3.2360e-41,  5.6946e-41, -5.8712e-40],\n",
      "          [ 5.8926e-40,  4.9621e-40, -4.9758e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.4709e-40,  5.6296e-40, -5.4689e-40],\n",
      "          [ 5.2594e-40,  6.1486e-40, -5.6839e-40],\n",
      "          [-1.6017e-42,  3.3906e-41,  5.3008e-40]],\n",
      "\n",
      "         [[ 3.7500e-40, -1.3022e-40,  8.9072e-41],\n",
      "          [ 4.5402e-43,  4.3847e-41, -3.6055e-41],\n",
      "          [ 4.8909e-40, -5.4446e-40, -1.1940e-41]],\n",
      "\n",
      "         [[ 5.0811e-40,  5.2854e-40, -5.8546e-40],\n",
      "          [-5.0705e-40,  5.7294e-40,  1.5156e-40],\n",
      "          [-4.3469e-40, -3.0715e-41,  5.7837e-40]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8254e-40,  6.0689e-40,  5.9640e-40],\n",
      "          [-4.8914e-40, -5.2261e-40,  1.2580e-40],\n",
      "          [ 2.6658e-40,  6.0949e-40, -3.3179e-41]],\n",
      "\n",
      "         [[-1.5272e-40,  5.9321e-40, -3.2247e-41],\n",
      "          [ 3.8398e-41,  4.3192e-40,  5.8569e-40],\n",
      "          [-4.4361e-40, -4.6009e-41,  1.7201e-41]],\n",
      "\n",
      "         [[ 6.1036e-40, -5.9049e-40, -6.1041e-42],\n",
      "          [-6.0827e-40, -2.5083e-43, -6.0799e-40],\n",
      "          [-5.0210e-40,  5.1184e-40,  5.1946e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3480e-42, -6.0622e-40, -4.9139e-40],\n",
      "          [-6.0069e-40,  6.2028e-40,  5.3645e-40],\n",
      "          [-5.5758e-40,  5.9513e-40,  3.6637e-40]],\n",
      "\n",
      "         [[-5.4530e-40,  4.1563e-41,  5.1470e-40],\n",
      "          [ 4.9687e-40,  4.9826e-40,  5.3429e-41],\n",
      "          [-4.8818e-40,  5.0593e-40,  5.8818e-40]],\n",
      "\n",
      "         [[ 5.8302e-40,  4.1034e-40,  9.2693e-41],\n",
      "          [ 4.8679e-40, -3.6034e-40, -5.1819e-40],\n",
      "          [ 3.7556e-40,  5.1461e-41, -1.9257e-40]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 5.4542e-40, -6.1130e-40, -1.6045e-40],\n",
      "          [-5.0372e-40,  3.4590e-41, -5.0876e-40],\n",
      "          [ 5.7129e-40, -1.1909e-40, -5.2077e-40]],\n",
      "\n",
      "         [[-5.4304e-40,  5.4656e-41, -5.7154e-40],\n",
      "          [ 4.8049e-40,  4.8803e-40,  6.0413e-40],\n",
      "          [ 3.1718e-41,  4.9203e-40, -5.4946e-40]],\n",
      "\n",
      "         [[-5.1555e-40,  6.1895e-40, -5.7498e-40],\n",
      "          [-3.6917e-40,  5.3406e-40,  2.5644e-42],\n",
      "          [-5.7212e-40,  5.1869e-40, -4.2403e-42]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5866e-40,  5.1948e-40, -5.4217e-40],\n",
      "          [ 5.8629e-40,  4.9633e-40, -5.7006e-41],\n",
      "          [ 5.8281e-40, -5.8019e-40,  5.1542e-40]],\n",
      "\n",
      "         [[-2.0421e-40, -5.5501e-40,  6.0108e-40],\n",
      "          [-5.8344e-40, -3.6056e-40,  5.6839e-40],\n",
      "          [ 1.1621e-41, -4.3735e-42, -1.9670e-40]],\n",
      "\n",
      "         [[-5.3003e-40,  6.1909e-40,  2.3821e-40],\n",
      "          [ 5.5789e-40, -4.5191e-40, -5.7757e-40],\n",
      "          [ 6.0975e-40,  4.5933e-40,  7.4752e-41]]],\n",
      "\n",
      "\n",
      "        [[[-5.8314e-40,  5.5262e-41, -2.1482e-42],\n",
      "          [-5.3993e-41, -3.4134e-41,  5.2063e-40],\n",
      "          [-4.4189e-41,  5.9246e-40, -2.6830e-40]],\n",
      "\n",
      "         [[-5.6474e-40,  3.9832e-40,  5.3862e-40],\n",
      "          [ 4.4932e-40, -4.2762e-41,  6.4023e-41],\n",
      "          [ 1.4784e-40, -6.1392e-41,  5.6070e-41]],\n",
      "\n",
      "         [[-5.1178e-40, -4.8980e-40, -5.0376e-40],\n",
      "          [-5.1557e-40, -5.3491e-40,  2.7519e-40],\n",
      "          [-6.0907e-41,  6.0373e-40, -5.3959e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.4206e-40,  5.3935e-40, -4.0600e-40],\n",
      "          [ 5.4142e-40,  5.2668e-40, -5.2191e-40],\n",
      "          [-1.3466e-41, -5.1983e-40, -3.4663e-40]],\n",
      "\n",
      "         [[ 4.3329e-40,  5.3184e-40, -5.2503e-40],\n",
      "          [ 5.2260e-40, -3.8332e-40, -5.0018e-40],\n",
      "          [-5.8657e-40,  2.1222e-40,  4.9308e-40]],\n",
      "\n",
      "         [[ 3.4606e-40,  9.8113e-41, -5.2601e-40],\n",
      "          [ 1.1978e-41,  4.9490e-40,  2.2251e-40],\n",
      "          [ 5.2263e-40, -6.1077e-40, -5.7191e-40]]],\n",
      "\n",
      "\n",
      "        [[[-3.5646e-40, -5.4799e-40,  5.3682e-40],\n",
      "          [ 2.4643e-40, -1.6171e-40, -4.3358e-41],\n",
      "          [ 4.9117e-40,  5.2666e-40,  5.0641e-40]],\n",
      "\n",
      "         [[-5.6669e-40, -6.1539e-41,  6.0135e-40],\n",
      "          [ 3.2331e-41, -5.0100e-40,  4.9483e-40],\n",
      "          [-6.1095e-40,  5.1428e-40,  5.2847e-40]],\n",
      "\n",
      "         [[ 1.6161e-40,  3.9836e-41,  6.0663e-40],\n",
      "          [-5.1635e-40,  3.4516e-40,  6.0875e-40],\n",
      "          [-5.1420e-40, -5.7607e-40, -2.9724e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.1065e-40, -4.9710e-40, -4.1380e-40],\n",
      "          [-5.0835e-40,  6.1383e-40,  5.1664e-40],\n",
      "          [ 1.5081e-40,  4.2297e-40, -1.0750e-40]],\n",
      "\n",
      "         [[ 4.2609e-40,  3.3253e-40,  5.3271e-40],\n",
      "          [ 5.8257e-40,  5.9435e-41, -5.9796e-40],\n",
      "          [-5.2299e-40,  4.8133e-41,  5.9744e-40]],\n",
      "\n",
      "         [[-5.6927e-40,  4.5503e-41,  5.2929e-40],\n",
      "          [-5.4013e-40, -4.5500e-40, -2.4072e-41],\n",
      "          [ 2.0734e-40, -6.1259e-40,  6.1542e-40]]]], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "features.16.bias : torch.Size([512])\n",
      "Parameter containing:\n",
      "tensor([ 4.1754e-33,  2.2097e-40,  3.0613e-40,  3.6657e-35,  4.0365e-40,\n",
      "        -4.5844e-33,  2.2508e-40, -5.7228e-40, -3.3689e-32, -4.8407e-40,\n",
      "         5.0182e-40, -6.4341e-34,  5.6987e-32, -5.0160e-40,  5.4624e-32,\n",
      "         7.6485e-34, -5.7545e-40,  5.7133e-33,  9.5970e-38,  1.6292e-34,\n",
      "         3.2964e-40, -5.1644e-40, -1.9693e-32,  2.3770e-40,  4.8460e-32,\n",
      "        -3.5955e-31, -1.1062e-37,  7.7819e-34, -2.5259e-32,  1.3596e-40,\n",
      "        -2.0324e-31, -5.5774e-40, -7.1781e-32, -8.1275e-39, -4.6663e-40,\n",
      "         1.2143e-40,  3.3493e-40, -8.9550e-41,  4.7261e-34,  4.9997e-40,\n",
      "        -7.2522e-36,  3.8719e-40, -1.2474e-35,  5.7273e-31,  5.2550e-40,\n",
      "        -1.7899e-38,  4.7237e-40,  1.6165e-40, -2.7024e-38,  7.0069e-32,\n",
      "         4.8539e-40,  6.4615e-30,  2.8734e-39,  1.2198e-32, -1.0459e-36,\n",
      "         1.9147e-40,  6.4268e-34,  9.1892e-32,  4.1667e-36,  8.5139e-41,\n",
      "        -3.2748e-40,  6.0162e-40, -5.3241e-35, -3.5587e-34, -5.9774e-40,\n",
      "        -5.4808e-40, -6.1112e-40,  3.2423e-40, -7.3874e-32, -5.7726e-40,\n",
      "        -1.9870e-34,  1.0783e-41, -2.3041e-36,  4.2767e-40,  8.5305e-39,\n",
      "        -4.9904e-40, -1.6645e-32,  5.8541e-40,  1.2628e-34,  5.2258e-40,\n",
      "         4.6574e-40, -1.2897e-39, -5.8150e-40,  1.4318e-40,  3.9193e-31,\n",
      "         4.6498e-36, -2.6971e-33,  2.8996e-34,  1.3942e-40,  4.2952e-40,\n",
      "        -4.1530e-32,  1.3020e-34, -6.0688e-40,  5.4572e-40,  2.2012e-33,\n",
      "        -4.9999e-40,  1.0034e-32,  4.9701e-40,  3.8831e-40, -4.8080e-40,\n",
      "        -5.6229e-33,  7.1644e-41,  5.1083e-40, -1.3671e-32, -4.3463e-40,\n",
      "        -4.8959e-40,  3.5265e-32, -9.1649e-39,  2.2946e-32, -5.7265e-40,\n",
      "         1.7239e-32,  3.3234e-40, -4.8952e-40, -5.5838e-40,  1.0230e-36,\n",
      "        -6.8099e-41,  3.7781e-30,  2.3845e-36, -4.6019e-40,  1.0822e-40,\n",
      "         7.0777e-37,  4.3195e-40, -8.4245e-41,  2.0705e-40, -2.2736e-39,\n",
      "         5.1005e-40,  4.7562e-35, -1.5745e-33,  4.7705e-40,  5.0377e-40,\n",
      "        -5.3225e-40,  2.2240e-33,  4.4846e-40,  3.8398e-40,  1.2294e-41,\n",
      "         5.4933e-40,  6.1031e-33, -3.3670e-36,  2.7142e-40,  5.9930e-40,\n",
      "         5.7670e-34, -5.6678e-32, -5.4527e-40,  3.1511e-41, -3.3085e-42,\n",
      "         5.1860e-40, -1.3522e-34, -1.7996e-40, -4.9368e-40,  2.1572e-32,\n",
      "        -1.1816e-32,  2.1914e-38, -4.8691e-37,  3.6622e-33, -2.1570e-40,\n",
      "         4.6158e-35,  1.0024e-36,  1.4522e-37,  5.5258e-40, -1.6832e-31,\n",
      "         2.0312e-32,  2.1909e-36, -5.4749e-40, -3.8848e-40,  3.3333e-33,\n",
      "        -4.8229e-40, -1.7118e-40,  3.1860e-33, -3.8139e-40,  5.1672e-40,\n",
      "         1.9992e-34, -5.3053e-40,  1.0837e-31,  3.2840e-37, -1.4190e-32,\n",
      "         2.6178e-34, -4.9351e-41, -9.8176e-36,  1.0223e-40,  2.6203e-34,\n",
      "         7.1512e-38,  3.3385e-33,  4.9448e-35, -6.4134e-36, -5.8345e-40,\n",
      "         3.4507e-40,  6.0427e-40,  1.3710e-31, -4.8497e-40,  4.9530e-40,\n",
      "         3.0246e-32, -3.4239e-40, -1.5378e-39,  1.5760e-31, -9.3761e-33,\n",
      "        -1.3903e-35,  2.6291e-36, -1.1188e-35, -3.0244e-32,  9.5204e-42,\n",
      "        -3.3739e-40, -7.4461e-40, -1.2736e-31,  5.3944e-40, -2.1064e-32,\n",
      "         3.5294e-33, -5.0760e-32, -8.6022e-41,  4.3733e-39,  6.2872e-41,\n",
      "         4.6915e-40,  1.8795e-34, -1.5202e-33, -3.7858e-34,  3.7636e-32,\n",
      "         1.3524e-33,  1.1374e-35, -3.3946e-32,  3.7127e-32,  1.8812e-32,\n",
      "         5.6034e-40, -5.4009e-40, -4.7745e-40, -1.5505e-41, -2.9739e-40,\n",
      "         5.2416e-40, -5.5905e-40,  1.4335e-31,  9.9841e-39, -1.7189e-40,\n",
      "        -6.7458e-36, -6.2077e-35, -3.9535e-33, -1.6495e-33,  4.5475e-34,\n",
      "         1.1518e-33,  2.3798e-38,  5.9289e-40,  3.1776e-41, -3.9004e-40,\n",
      "        -1.5052e-38,  1.5103e-40,  4.2284e-40, -3.3971e-33, -1.7026e-33,\n",
      "        -5.4822e-40, -2.0208e-40,  3.3097e-39,  4.9708e-40,  5.8053e-40,\n",
      "         1.8786e-41,  2.2728e-41, -1.6062e-39, -8.2878e-38,  6.8144e-32,\n",
      "         5.6446e-40, -3.5730e-40, -1.4072e-34,  8.5012e-35,  3.8305e-40,\n",
      "        -1.7420e-40,  6.3112e-31, -4.6862e-32, -1.7144e-35, -4.7196e-40,\n",
      "         2.3361e-39,  4.9859e-40, -4.4691e-40, -1.6716e-41, -9.4177e-38,\n",
      "         2.7498e-34, -1.1834e-40,  7.8802e-38,  4.5412e-40, -5.4886e-40,\n",
      "         5.1551e-40,  5.6699e-40,  9.0168e-34,  2.0550e-40,  1.9223e-32,\n",
      "         2.5167e-38,  2.4660e-33, -6.4735e-40,  9.1152e-32,  1.4157e-40,\n",
      "        -2.8458e-39, -4.9967e-40,  1.3026e-35,  2.1401e-40, -1.6100e-39,\n",
      "         2.1792e-40,  3.1111e-37, -8.8308e-37,  2.8579e-40,  1.5543e-33,\n",
      "         4.3346e-34,  5.1412e-40,  3.5809e-31, -2.0967e-37, -5.9541e-40,\n",
      "        -2.5220e-32, -1.1535e-37, -3.6669e-40,  4.7990e-39,  2.1346e-41,\n",
      "         5.4108e-35,  7.0639e-33,  4.6086e-40,  8.2943e-39, -8.0620e-36,\n",
      "         2.8806e-37,  2.8143e-33, -1.9241e-33,  4.1821e-33, -7.0134e-37,\n",
      "        -4.1487e-32,  4.4151e-37, -5.5712e-40, -1.9567e-37, -6.4207e-41,\n",
      "         2.7441e-33, -1.1932e-37,  3.2846e-40, -4.4091e-40,  5.8740e-40,\n",
      "        -1.9441e-33, -5.3440e-41, -4.0113e-36, -5.8866e-40,  1.4276e-41,\n",
      "         5.3503e-40, -2.4297e-32,  3.6621e-38, -3.3943e-40, -5.4622e-40,\n",
      "        -5.1122e-40, -7.0240e-41,  9.4226e-41,  1.6215e-37,  7.3286e-39,\n",
      "         5.1171e-40, -7.3975e-36, -5.5112e-40, -2.5287e-40, -2.4350e-37,\n",
      "         2.8397e-31,  3.9445e-41, -8.2680e-33,  4.0317e-32,  7.0934e-41,\n",
      "         4.2251e-40, -2.6928e-33,  3.2638e-37, -2.0759e-40,  6.0092e-40,\n",
      "         1.2138e-37, -1.0348e-35, -1.9765e-32, -7.4450e-38,  4.8916e-40,\n",
      "        -1.5224e-40,  4.9886e-40, -5.0663e-40,  1.5715e-33, -5.5029e-40,\n",
      "        -3.5570e-40,  4.6392e-40,  1.6104e-38,  2.8401e-32, -8.6401e-34,\n",
      "        -1.1351e-37,  4.1053e-40,  4.5898e-34,  7.8057e-31,  4.5385e-32,\n",
      "        -4.9192e-32,  5.3371e-40, -1.2797e-40,  5.7918e-35,  1.0984e-40,\n",
      "         4.5289e-35, -1.0107e-31, -4.7711e-31, -4.2570e-40, -5.3431e-40,\n",
      "        -9.3149e-35, -4.3426e-35,  4.3153e-31,  5.9972e-40,  5.1546e-40,\n",
      "        -2.2375e-40, -9.3101e-33, -4.5673e-39,  9.6512e-36, -2.1986e-40,\n",
      "        -2.5417e-32, -1.3038e-40, -4.9083e-40, -3.0838e-40, -2.5771e-35,\n",
      "        -4.2949e-33,  3.1424e-40, -5.7812e-40, -9.6785e-41,  2.4952e-40,\n",
      "         1.3179e-41,  5.9727e-40,  4.3356e-36, -2.0258e-32,  1.0896e-40,\n",
      "         3.9812e-39, -5.4343e-37,  3.8034e-39,  2.6414e-33,  3.8981e-41,\n",
      "         5.7086e-38, -8.8873e-31, -1.6045e-40,  1.1784e-40, -1.3991e-40,\n",
      "         3.1431e-42,  4.6408e-40,  3.9797e-38,  1.1156e-33, -2.3590e-40,\n",
      "        -4.0131e-40,  1.3673e-35,  1.5905e-41, -5.4753e-40,  1.7386e-40,\n",
      "        -5.1547e-32,  4.3959e-40,  5.8432e-36,  5.4131e-40, -8.1012e-41,\n",
      "         4.9785e-33,  9.9248e-41, -3.1640e-40, -1.6003e-35, -5.0244e-40,\n",
      "         5.2895e-40,  4.3266e-32,  3.6929e-40, -4.2316e-40,  6.3284e-35,\n",
      "        -1.5151e-40,  1.2540e-32, -3.5000e-34, -9.3138e-35,  8.3621e-32,\n",
      "         2.3351e-40, -2.2178e-40, -1.3138e-35, -4.6957e-40, -3.2232e-32,\n",
      "         5.6659e-40,  1.5121e-32,  5.2927e-40,  6.2657e-32, -1.8315e-40,\n",
      "         9.4173e-39,  7.9541e-32, -5.3704e-40, -1.8633e-34,  4.5936e-33,\n",
      "        -2.5091e-32, -1.2479e-37,  2.4881e-35, -4.9984e-40, -2.2883e-40,\n",
      "         4.1009e-40,  8.2402e-32, -4.7420e-35, -1.6175e-40,  2.8890e-31,\n",
      "         1.0147e-36, -5.2524e-40,  3.2085e-33,  2.9220e-38,  1.4987e-33,\n",
      "         3.2393e-40,  5.3962e-40,  7.4177e-32, -3.9127e-40,  2.5396e-33,\n",
      "         2.4012e-40, -5.4014e-36, -4.8719e-40, -1.9943e-34, -5.0909e-34,\n",
      "        -8.8616e-33,  2.4890e-40, -4.7554e-39, -2.5293e-33,  2.9098e-31,\n",
      "        -2.8786e-40,  2.2194e-32,  1.1767e-34, -1.2117e-36, -1.8748e-32,\n",
      "         7.2912e-40, -2.5917e-34,  1.7103e-37, -6.8190e-37,  5.1319e-40,\n",
      "         4.3930e-40, -2.6334e-30, -1.7314e-38, -1.8776e-31, -1.4914e-41,\n",
      "        -4.8730e-40, -1.1077e-35], device='cuda:1', requires_grad=True)\n",
      "features.18.weight : torch.Size([512, 512, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([[[[-3.6820e-40,  5.1741e-40, -7.4480e-41],\n",
      "          [-5.7669e-40, -3.8452e-40,  9.9829e-42],\n",
      "          [ 1.6263e-40,  5.2774e-40,  2.2095e-40]],\n",
      "\n",
      "         [[-5.2283e-40,  5.6754e-40, -4.9981e-40],\n",
      "          [-5.8965e-40, -2.0070e-40, -5.5293e-40],\n",
      "          [ 5.0804e-40, -5.7772e-40, -5.0538e-41]],\n",
      "\n",
      "         [[-5.7961e-40,  4.4317e-40, -5.2601e-40],\n",
      "          [-5.9026e-40, -6.1867e-40,  3.7371e-40],\n",
      "          [-5.4690e-41, -4.5881e-41, -5.7763e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.8641e-42,  1.6284e-40,  5.5790e-40],\n",
      "          [ 5.3153e-40, -5.5487e-40,  4.9596e-40],\n",
      "          [ 5.8538e-40,  5.8692e-40,  5.0943e-40]],\n",
      "\n",
      "         [[-1.1530e-40,  6.7299e-41,  6.1954e-40],\n",
      "          [-4.9934e-40, -5.5233e-40, -5.3631e-40],\n",
      "          [-5.4189e-40,  5.7609e-40,  5.5312e-40]],\n",
      "\n",
      "         [[-6.1321e-40, -5.1115e-41, -5.4709e-40],\n",
      "          [ 5.1226e-40,  5.5598e-40,  5.4491e-40],\n",
      "          [-5.4453e-40,  4.9260e-41, -5.4152e-40]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4227e-40,  5.4490e-40,  5.6640e-40],\n",
      "          [ 5.1948e-40, -6.0441e-40, -4.8022e-40],\n",
      "          [ 6.0538e-40,  6.2341e-41, -5.5696e-40]],\n",
      "\n",
      "         [[-6.1806e-40,  4.9731e-40, -5.1924e-40],\n",
      "          [-5.4014e-41,  6.1798e-40, -4.9401e-41],\n",
      "          [ 3.6259e-40,  6.1513e-40, -5.8695e-40]],\n",
      "\n",
      "         [[ 5.2130e-40,  3.9663e-40,  5.0213e-40],\n",
      "          [-5.5102e-41,  2.9604e-41, -5.5701e-40],\n",
      "          [-1.7730e-40,  4.8772e-40, -3.1218e-41]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.9803e-40, -5.0081e-40,  4.8846e-40],\n",
      "          [ 2.0809e-42,  6.0144e-40, -5.0459e-40],\n",
      "          [-1.0871e-41, -6.9196e-42, -4.1911e-40]],\n",
      "\n",
      "         [[-5.8682e-40, -5.9051e-40, -4.4269e-40],\n",
      "          [ 3.5694e-40, -5.5159e-40,  6.0585e-40],\n",
      "          [-5.5539e-40,  6.1293e-40, -1.6025e-40]],\n",
      "\n",
      "         [[ 4.3358e-40,  3.8331e-40,  5.7981e-40],\n",
      "          [ 5.0891e-40,  7.3606e-41,  6.0140e-40],\n",
      "          [-6.2108e-40, -6.0780e-40, -5.8382e-41]]],\n",
      "\n",
      "\n",
      "        [[[-1.6320e-40, -6.0584e-40,  6.2184e-40],\n",
      "          [-1.2212e-41,  5.6982e-40,  3.2179e-41],\n",
      "          [-6.1106e-40,  4.8924e-41, -5.6983e-40]],\n",
      "\n",
      "         [[-1.4803e-41,  5.2806e-40, -5.2127e-40],\n",
      "          [ 5.4218e-40, -5.9553e-40,  5.1381e-40],\n",
      "          [ 6.0736e-40, -2.2850e-40,  1.9939e-40]],\n",
      "\n",
      "         [[-5.5529e-40, -2.9207e-41,  4.4861e-40],\n",
      "          [-3.8086e-40, -3.5649e-41, -5.6025e-40],\n",
      "          [-9.1883e-41, -3.7206e-40, -5.0718e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.7869e-40,  3.6448e-42,  2.4596e-40],\n",
      "          [-5.6804e-40,  5.7411e-40,  4.9324e-40],\n",
      "          [ 5.9387e-40,  5.8503e-40, -3.3191e-41]],\n",
      "\n",
      "         [[ 3.9020e-40,  5.1346e-40, -5.8935e-40],\n",
      "          [-4.5855e-40, -3.3605e-40,  5.4067e-40],\n",
      "          [-4.3655e-40, -7.6957e-41, -5.7200e-40]],\n",
      "\n",
      "         [[ 5.6779e-40,  5.4044e-41,  1.9454e-40],\n",
      "          [-7.5390e-43, -1.4588e-41, -5.7164e-40],\n",
      "          [ 3.4843e-40,  5.3500e-40, -5.6254e-40]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.4805e-42,  5.7646e-40,  2.3481e-40],\n",
      "          [-1.2852e-40,  5.8567e-40,  5.1256e-40],\n",
      "          [-1.3785e-41, -5.3236e-40,  3.2404e-40]],\n",
      "\n",
      "         [[-5.7298e-40, -6.1534e-40,  3.2747e-41],\n",
      "          [-5.3966e-40, -2.1305e-40,  5.8635e-40],\n",
      "          [-1.0232e-40, -5.5767e-40,  6.1914e-40]],\n",
      "\n",
      "         [[-5.5312e-41, -6.1286e-40,  5.7577e-40],\n",
      "          [ 5.4122e-41,  5.6500e-40,  4.2710e-41],\n",
      "          [-5.0106e-40, -5.5566e-40,  5.0357e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.8337e-40, -4.5174e-41,  4.8409e-40],\n",
      "          [ 5.9736e-40, -1.2076e-41,  3.6924e-41],\n",
      "          [-8.9617e-41,  1.3440e-41,  4.9733e-40]],\n",
      "\n",
      "         [[-5.0105e-40,  5.8437e-40,  5.1447e-40],\n",
      "          [ 5.3158e-40,  3.5108e-40, -3.8972e-41],\n",
      "          [ 5.6769e-40,  2.5330e-41, -6.1248e-41]],\n",
      "\n",
      "         [[ 4.9145e-40, -5.1935e-41, -6.0947e-40],\n",
      "          [-5.2504e-40, -3.2289e-40, -5.5979e-41],\n",
      "          [ 5.8939e-40, -6.0755e-40,  5.1477e-40]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6157e-40, -4.3451e-40, -5.2317e-40],\n",
      "          [-5.2985e-40, -8.3517e-42, -2.5574e-42],\n",
      "          [ 5.9526e-40, -5.1800e-40, -6.0341e-40]],\n",
      "\n",
      "         [[-1.8193e-41,  5.4149e-40, -3.6376e-40],\n",
      "          [-5.0672e-40, -5.6793e-40,  4.8426e-40],\n",
      "          [-2.2575e-42,  4.3853e-40, -3.3530e-41]],\n",
      "\n",
      "         [[-5.0679e-40, -5.1628e-40, -4.3747e-41],\n",
      "          [ 5.2528e-40, -3.7846e-40, -4.3209e-40],\n",
      "          [ 1.2196e-41, -2.9823e-40, -1.8479e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.8215e-40, -4.9263e-40, -1.4141e-40],\n",
      "          [ 1.5843e-40,  6.0359e-40, -2.7747e-40],\n",
      "          [-5.7350e-40, -6.1326e-40, -1.0359e-40]],\n",
      "\n",
      "         [[-7.5663e-41, -1.1785e-41,  2.2866e-41],\n",
      "          [-5.2807e-40,  5.3896e-40, -1.1888e-40],\n",
      "          [-6.0387e-40,  5.0057e-40,  6.4199e-41]],\n",
      "\n",
      "         [[ 5.4338e-40,  5.7804e-40, -5.8590e-40],\n",
      "          [-3.8157e-42,  6.0754e-40,  6.1926e-40],\n",
      "          [-4.1813e-40, -5.2125e-40,  6.2153e-40]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7828e-40,  1.7480e-40,  3.8903e-41],\n",
      "          [ 5.0428e-40, -2.2519e-40,  5.0288e-40],\n",
      "          [-6.0197e-41, -4.1451e-40, -9.9013e-41]],\n",
      "\n",
      "         [[-8.9390e-41, -5.2081e-40, -5.5994e-40],\n",
      "          [-8.5101e-42, -4.9661e-40,  5.0960e-40],\n",
      "          [-5.1843e-40,  5.1824e-40, -5.7938e-40]],\n",
      "\n",
      "         [[ 5.0483e-40,  1.3098e-41,  1.9963e-40],\n",
      "          [-4.9264e-41,  4.9383e-40,  5.9548e-40],\n",
      "          [ 1.6681e-40,  2.0487e-40,  5.5309e-40]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.5633e-42, -3.1539e-41, -4.6632e-41],\n",
      "          [ 5.6801e-40, -2.7326e-40, -5.9073e-40],\n",
      "          [-6.0578e-40,  4.4000e-40, -5.2609e-40]],\n",
      "\n",
      "         [[-5.1463e-40,  5.8083e-40, -1.0488e-40],\n",
      "          [-5.6366e-40,  3.7374e-41, -2.1438e-40],\n",
      "          [-3.5950e-41, -6.1767e-40, -5.7397e-40]],\n",
      "\n",
      "         [[-6.2635e-41, -5.1742e-40,  5.1788e-41],\n",
      "          [ 4.8887e-40, -5.1248e-40, -5.5923e-40],\n",
      "          [ 6.1015e-40, -5.7311e-40, -5.9000e-40]]]], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "features.18.bias : torch.Size([512])\n",
      "Parameter containing:\n",
      "tensor([-4.1792e-35,  2.1383e-35, -1.6244e-40,  5.0434e-40,  3.5951e-39,\n",
      "         6.1749e-40,  1.6665e-36, -4.2266e-41,  1.1221e-36,  5.0265e-42,\n",
      "        -4.8874e-40,  1.3082e-33, -4.5289e-38, -2.0774e-36, -2.2315e-40,\n",
      "         8.5922e-34, -1.4772e-34, -2.3011e-40, -5.7291e-40, -6.4518e-35,\n",
      "         4.7365e-37, -2.6928e-34, -9.4756e-29, -7.1693e-35,  4.1226e-28,\n",
      "        -4.2394e-40, -1.3941e-32,  4.9380e-35, -5.3834e-33,  4.3933e-40,\n",
      "         3.5271e-40,  5.0645e-40,  2.7806e-36,  1.4646e-32, -5.0059e-40,\n",
      "        -1.7673e-34,  2.4123e-40,  3.2959e-39,  6.3772e-31,  4.8731e-40,\n",
      "        -5.3122e-40,  3.3080e-28,  5.4339e-40,  2.1213e-41, -8.8590e-42,\n",
      "         4.0922e-40,  1.4690e-40,  3.3012e-27, -5.9353e-40, -3.3067e-28,\n",
      "        -5.3924e-40,  5.8977e-40,  1.3005e-40,  4.2183e-33, -1.8860e-40,\n",
      "         3.7957e-36, -5.8928e-36,  3.1854e-40,  3.0855e-40, -5.9489e-40,\n",
      "         7.0746e-30,  7.5721e-41, -2.9186e-33, -3.2202e-40,  6.5219e-30,\n",
      "        -6.1439e-30, -2.4950e-39,  3.5541e-41, -8.1013e-39,  5.4537e-40,\n",
      "         4.9837e-40,  5.2860e-40, -2.1329e-27, -2.1373e-34,  3.3215e-40,\n",
      "         2.7201e-28,  1.5218e-36,  6.8731e-36,  2.1048e-40,  6.3893e-35,\n",
      "         4.2291e-28, -1.8939e-40, -7.8246e-28,  5.7351e-40, -1.3311e-29,\n",
      "        -3.0076e-34,  1.9101e-35, -2.6636e-37,  4.2927e-38,  1.3197e-40,\n",
      "         5.8936e-40, -6.2359e-38,  1.7596e-40, -1.6993e-33,  3.3740e-34,\n",
      "        -2.0460e-40,  5.5466e-40, -3.5746e-40,  9.2605e-34,  5.3767e-40,\n",
      "        -7.6787e-41,  5.0454e-40,  3.4105e-40, -1.7112e-30, -5.8715e-40,\n",
      "         3.3944e-40, -2.7164e-31, -2.8668e-37, -4.1128e-37, -2.8009e-33,\n",
      "        -3.1155e-39,  5.4573e-40,  5.8556e-40, -8.3145e-33, -1.8870e-34,\n",
      "         1.9167e-32, -6.0332e-40,  4.7596e-40, -2.0223e-40,  3.2422e-30,\n",
      "         4.6822e-40, -3.0802e-39,  4.0784e-40, -8.3354e-28,  5.8099e-40,\n",
      "        -6.5999e-34, -2.1579e-35,  4.7572e-31,  8.4968e-38,  1.8480e-29,\n",
      "        -1.1503e-41, -4.5060e-40,  4.6743e-40,  6.8135e-30, -3.7997e-40,\n",
      "        -8.3432e-29, -4.8563e-40,  3.0868e-40,  3.1161e-35, -1.2623e-27,\n",
      "         2.7126e-28, -1.1086e-29,  3.5582e-33, -5.6492e-40,  4.8272e-40,\n",
      "         1.5174e-35,  3.1319e-29,  3.6612e-27,  7.9085e-36,  1.7028e-38,\n",
      "         1.7034e-37,  5.9180e-40,  6.9033e-37, -1.9209e-40,  5.9955e-40,\n",
      "        -3.1047e-33, -3.0813e-27, -6.8787e-29,  1.9243e-37, -6.3794e-38,\n",
      "        -9.5896e-36, -4.8298e-40,  4.9476e-37, -1.7151e-40, -5.3543e-40,\n",
      "         4.5860e-40,  5.3812e-40,  7.4493e-29,  4.2633e-35,  2.0082e-40,\n",
      "         3.5674e-32,  4.4577e-40,  5.7855e-40,  2.5047e-30, -5.2773e-40,\n",
      "         3.5994e-32, -1.1810e-28,  2.2699e-27, -1.0320e-39, -1.7395e-31,\n",
      "         1.7643e-27, -1.0517e-33, -9.5737e-38,  1.5454e-34,  1.3847e-40,\n",
      "         3.3901e-40, -6.1606e-34, -5.4533e-40,  1.0103e-40,  4.9684e-40,\n",
      "        -4.6447e-35, -5.2092e-40, -4.5953e-40,  5.9141e-40,  3.5642e-34,\n",
      "         5.1351e-40,  1.5767e-40,  1.5512e-30, -4.3020e-40, -2.6377e-30,\n",
      "         1.1463e-35,  1.4226e-27, -2.6682e-35,  8.6475e-37,  8.2708e-31,\n",
      "         1.0675e-40,  4.0121e-29,  7.5848e-40, -6.8329e-35, -2.1155e-28,\n",
      "        -1.4211e-33,  5.2009e-40, -1.0594e-32,  4.7462e-31,  5.8338e-40,\n",
      "        -8.0825e-41,  9.9801e-36,  1.7648e-28,  4.2074e-31, -2.5306e-40,\n",
      "         3.1816e-29,  1.4236e-28,  5.3040e-40, -4.7713e-40,  6.5326e-34,\n",
      "         1.9193e-40, -3.1968e-34,  2.9712e-40,  2.0774e-32,  4.8492e-40,\n",
      "         5.4359e-40, -1.0888e-27,  5.3747e-40,  4.5807e-30,  6.9766e-34,\n",
      "        -3.1171e-32,  4.7607e-40,  3.3216e-29,  1.5928e-29, -9.0256e-32,\n",
      "         1.5366e-37, -5.5019e-40,  2.1754e-30,  1.8111e-28,  1.6327e-35,\n",
      "         1.7365e-32, -5.3126e-36, -1.5840e-33, -1.1255e-27, -4.4329e-40,\n",
      "         3.1711e-33, -2.6332e-34,  2.1023e-40,  1.3797e-33, -3.7338e-40,\n",
      "        -4.7464e-40, -4.9412e-40,  3.4003e-40, -3.1303e-28,  3.9860e-40,\n",
      "         5.6021e-40,  4.7163e-27,  1.0106e-33, -1.1739e-36, -1.2656e-27,\n",
      "         3.1917e-35, -1.2517e-40, -5.8399e-28,  5.9091e-40,  1.4252e-35,\n",
      "         2.6352e-35,  5.4985e-40, -1.4531e-32, -1.8802e-32, -1.4626e-35,\n",
      "        -5.1271e-41, -6.1135e-40,  5.9883e-40, -5.8423e-40, -2.0176e-27,\n",
      "        -1.1125e-36, -5.4407e-40, -3.0592e-36,  6.5254e-40, -1.5599e-36,\n",
      "        -7.6333e-41,  2.2508e-40,  4.6202e-40, -2.4776e-33,  5.7271e-37,\n",
      "        -5.9663e-40, -5.9052e-40, -4.0893e-34,  5.1253e-40, -1.8418e-33,\n",
      "         4.4794e-29, -6.4767e-28,  5.6094e-40, -8.1015e-29, -1.5599e-36,\n",
      "        -5.5375e-40,  3.4843e-37,  4.7013e-35,  5.2753e-41, -5.4314e-40,\n",
      "        -4.5481e-40,  4.5020e-36, -5.3461e-40,  1.7632e-40,  8.8545e-41,\n",
      "         5.3114e-40,  3.8122e-39,  1.0231e-34,  2.3621e-28,  2.3073e-40,\n",
      "        -2.9221e-40,  1.3084e-27, -1.6194e-38, -1.7026e-33,  5.4301e-40,\n",
      "        -1.5738e-35, -3.3219e-40, -7.8576e-35, -5.3551e-27, -2.2429e-40,\n",
      "        -1.5238e-40,  1.3927e-31,  1.1224e-29, -3.1361e-40, -1.6737e-35,\n",
      "         1.2506e-27, -4.2207e-30, -1.0501e-28, -1.5886e-40, -4.1786e-40,\n",
      "        -5.5959e-40, -2.1503e-29,  5.4389e-40,  2.8302e-38,  5.7907e-40,\n",
      "         2.0562e-34, -3.8939e-34, -2.3696e-31, -4.7820e-40,  2.5768e-39,\n",
      "        -1.1061e-31,  6.8369e-42,  5.2732e-40,  5.0767e-35,  2.0898e-36,\n",
      "         4.0636e-40,  2.1951e-40,  1.6348e-32,  2.4884e-40, -6.1544e-34,\n",
      "         2.1084e-32,  1.0656e-34, -1.2578e-33,  1.9066e-40, -1.8401e-36,\n",
      "         4.5287e-40, -6.1817e-31,  6.6801e-41, -2.5726e-35,  1.3180e-37,\n",
      "        -2.1196e-37,  7.7352e-43,  4.1093e-40,  1.1303e-33, -1.2000e-30,\n",
      "         5.1335e-40,  1.1965e-28, -1.8386e-40, -1.2827e-34, -5.5789e-31,\n",
      "        -1.7556e-39,  3.7060e-40,  2.0338e-28,  5.3631e-40, -3.7166e-33,\n",
      "         1.8970e-35, -8.6689e-35, -3.4366e-37, -3.2736e-39, -6.1031e-30,\n",
      "         1.9074e-37, -4.8215e-40, -7.6911e-33, -1.9316e-28,  9.9838e-39,\n",
      "        -6.1489e-41, -7.7595e-29, -5.0845e-40, -4.0989e-29, -2.2131e-28,\n",
      "         4.0013e-41,  5.6722e-38,  3.9060e-41,  8.9628e-28, -2.2351e-30,\n",
      "         1.1212e-38, -5.5495e-40,  5.1855e-40,  1.0804e-42, -3.5955e-35,\n",
      "         5.7026e-40, -8.4908e-37,  3.5531e-29, -2.1979e-40, -4.4353e-36,\n",
      "        -2.0358e-36, -1.2806e-37,  3.6274e-40,  2.8324e-30, -1.8978e-27,\n",
      "        -3.8268e-40, -5.4454e-40, -1.6518e-28,  5.6358e-40,  3.0771e-40,\n",
      "         2.7438e-27, -4.6357e-40,  3.1219e-29, -1.2733e-34,  2.2260e-33,\n",
      "         1.0495e-34, -3.6383e-35, -1.3189e-28, -7.6819e-38,  5.5151e-40,\n",
      "        -5.5089e-34, -4.2539e-37,  4.3832e-34, -7.9888e-42, -1.5094e-34,\n",
      "         1.9554e-33,  4.9868e-40,  7.5228e-36, -5.3019e-40, -5.8862e-40,\n",
      "         1.4805e-30, -4.4447e-40, -6.5351e-34,  2.3849e-32, -3.5293e-40,\n",
      "         3.5991e-37, -3.2032e-30, -3.7354e-34,  2.8308e-40,  3.9231e-41,\n",
      "         8.3768e-35,  1.6003e-27,  7.0239e-28,  5.1428e-28,  1.0450e-31,\n",
      "        -2.3094e-40, -8.4029e-41,  8.1204e-41, -6.2976e-41, -3.5249e-40,\n",
      "        -2.2404e-40, -5.1355e-40, -4.5137e-40,  6.0551e-40, -2.4372e-40,\n",
      "        -1.4361e-28, -3.0254e-39, -3.2666e-28,  1.1697e-32,  1.6244e-27,\n",
      "         5.3266e-40,  5.4627e-40, -4.7497e-32,  9.3714e-30, -5.9292e-35,\n",
      "         5.4547e-40, -1.2845e-40,  1.2103e-38, -5.5675e-40, -6.1456e-40,\n",
      "        -3.0186e-40, -9.4058e-29, -1.6789e-28, -3.4517e-40, -5.2501e-40,\n",
      "         1.0009e-31, -3.2347e-40,  2.3477e-30, -1.9675e-40, -5.1980e-40,\n",
      "        -2.0802e-40, -1.9205e-35, -5.7270e-40,  1.0709e-41,  5.7141e-37,\n",
      "         3.8406e-34, -1.4990e-39, -1.9884e-31,  1.8723e-29,  5.2764e-38,\n",
      "         5.8499e-40, -4.9561e-40,  5.3504e-38, -3.6463e-36,  7.4322e-27,\n",
      "        -2.3022e-34,  2.8456e-35,  3.9662e-40, -6.3113e-41,  3.6854e-29,\n",
      "         5.7665e-40,  3.6205e-40], device='cuda:1', requires_grad=True)\n",
      "classifier.0.weight : torch.Size([2304, 12800])\n",
      "Parameter containing:\n",
      "tensor([[-2.1119e-40, -3.5101e-40, -5.6917e-40,  ..., -3.8587e-40,\n",
      "          1.0794e-40,  3.3591e-40],\n",
      "        [ 3.8174e-40, -5.0397e-40,  5.8127e-40,  ...,  5.1923e-40,\n",
      "          6.0038e-40, -6.4032e-41],\n",
      "        [ 1.6573e-41,  5.1583e-40, -1.1280e-42,  ..., -4.1150e-40,\n",
      "          6.0452e-40, -4.4657e-41],\n",
      "        ...,\n",
      "        [-4.5561e-40, -6.0664e-40,  6.0137e-40,  ..., -4.7993e-41,\n",
      "         -5.0294e-40,  3.3799e-42],\n",
      "        [ 5.8566e-40,  5.2831e-40, -6.1080e-40,  ..., -6.0368e-40,\n",
      "          5.9171e-40, -1.6375e-40],\n",
      "        [ 4.0469e-41, -6.1765e-40,  5.5322e-40,  ..., -4.1919e-40,\n",
      "          7.3952e-41,  2.3598e-42]], device='cuda:1', requires_grad=True)\n",
      "classifier.0.bias : torch.Size([2304])\n",
      "Parameter containing:\n",
      "tensor([-1.8986e-36,  4.3706e-34,  6.3679e-36,  ..., -2.4558e-33,\n",
      "         4.5393e-36,  1.0079e-34], device='cuda:1', requires_grad=True)\n",
      "classifier.2.weight : torch.Size([2304, 2304])\n",
      "Parameter containing:\n",
      "tensor([[ 6.2324e-38,  1.0408e-35,  1.0807e-37,  ..., -8.0362e-35,\n",
      "         -1.4768e-37,  4.2408e-38],\n",
      "        [-5.5734e-40,  2.4372e-36, -9.0389e-38,  ..., -1.1025e-34,\n",
      "         -1.7212e-37,  3.9576e-36],\n",
      "        [-1.8334e-35, -5.9372e-34,  2.5204e-36,  ...,  9.9715e-36,\n",
      "         -5.5811e-35, -8.2903e-35],\n",
      "        ...,\n",
      "        [ 1.8672e-36, -4.0250e-34, -1.1716e-35,  ...,  2.0926e-33,\n",
      "          1.5430e-36,  1.1522e-36],\n",
      "        [ 1.8637e-36, -3.6416e-34, -1.1778e-35,  ...,  2.0866e-33,\n",
      "          1.5829e-36,  1.1182e-36],\n",
      "        [-6.5447e-37,  3.4531e-34,  8.7661e-36,  ...,  9.9425e-34,\n",
      "          1.2137e-38,  3.7663e-36]], device='cuda:1', requires_grad=True)\n",
      "classifier.2.bias : torch.Size([2304])\n",
      "Parameter containing:\n",
      "tensor([-4.7423e-05, -7.3655e-04, -9.4474e-03,  ..., -9.6578e-03,\n",
      "        -9.6578e-03, -9.6445e-03], device='cuda:1', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name,parameters in model.named_parameters():\n",
    "    print(name,':',parameters.size())\n",
    "    print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y torch.Size([32, 1000])\n",
      "y1 torch.Size([32, 512, 8, 8])\n",
      "y2 torch.Size([32, 512, 7, 7])\n",
      "y2 torch.Size([32, 25088])\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "y3 torch.Size([32, 1000])\n",
      "<class 'torch.nn.modules.container.Sequential'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [32 x 25088], m2: [2000 x 4096] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:136",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-2ce7188d3dc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         )\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0my4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpart3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m#y4=nn.Linear(2000, 4096)(y2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y4:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/are/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/are/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/are/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/are/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/are/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [32 x 25088], m2: [2000 x 4096] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:136"
     ]
    }
   ],
   "source": [
    "##表示疑惑？为什么直接加模型的part是可以linear不跟前面相关，而自己写是需要相关的\n",
    "model.classifier[0].in_features=2000\n",
    "x=torch.rand((32,3,256,256))\n",
    "y=model(x)\n",
    "print('y',y.shape)\n",
    "y1=model.features(x)\n",
    "print('y1',y1.shape)\n",
    "y2=model.avgpool(y1)\n",
    "print('y2',y2.shape)\n",
    "y2=torch.flatten(y2,1)\n",
    "print('y2',y2.shape)\n",
    "print(type(model.classifier))\n",
    "y3=model.classifier(y2)\n",
    "print('y3',y3.shape)\n",
    "\n",
    "part3=nn.Sequential(\n",
    "            nn.Linear(2000, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 1000),\n",
    "        )\n",
    "print(type(part3))\n",
    "y4=part3(y2)\n",
    "#y4=nn.Linear(2000, 4096)(y2)\n",
    "print('y4:',y4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
